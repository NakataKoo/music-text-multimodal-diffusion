{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoDi()のインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m236866/.conda/envs/codi/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from core.models import codi\n",
    "from core.models.ema import LitEma\n",
    "from core.models.common.get_optimizer import get_optimizer\n",
    "from argparse import ArgumentParser\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from core.models.common.get_model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml_config(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "class ConfigObject(object):\n",
    "    def __init__(self, dictionary):\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_define():\n",
    "    # AudioLDM\n",
    "    audioldm_cfg = load_yaml_config('configs/model/audioldm.yaml')\n",
    "    audioldm = ConfigObject(audioldm_cfg[\"audioldm_autoencoder\"])\n",
    "\n",
    "    # Optimus\n",
    "    optimus_cfg = load_yaml_config('configs/model/optimus.yaml')\n",
    "\n",
    "    # optimus_vaeのconfigの辞書を、オブジェクトに置き換え\n",
    "    optimus_cfg['optimus_vae']['args']['encoder'] = ConfigObject(optimus_cfg['optimus_bert_encoder'])\n",
    "    optimus_cfg['optimus_vae']['args']['encoder'].args['config'] = ConfigObject(optimus_cfg['optimus_bert_encoder']['args']['config'])\n",
    "    optimus_cfg['optimus_vae']['args']['decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder'])\n",
    "    optimus_cfg['optimus_vae']['args']['decoder'].args['config'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder']['args']['config'])\n",
    "    optimus_cfg['optimus_vae']['args']['tokenizer_encoder'] = ConfigObject(optimus_cfg['optimus_bert_tokenizer'])\n",
    "    optimus_cfg['optimus_vae']['args']['tokenizer_decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_tokenizer'])\n",
    "    optimus_cfg['optimus_vae']['args']['args'] = ConfigObject(optimus_cfg['optimus_vae']['args']['args'])\n",
    "    optimus = ConfigObject(optimus_cfg[\"optimus_vae\"])\n",
    "\n",
    "    # CLAP\n",
    "    clap_cfg = load_yaml_config('configs/model/clap.yaml')\n",
    "    clap = ConfigObject(clap_cfg[\"clap_audio\"])\n",
    "\n",
    "    # Unet\n",
    "    unet_cfg = load_yaml_config('configs/model/openai_unet.yaml')\n",
    "    #unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_image_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d\"])\n",
    "    unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_text_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_0dmd\"])\n",
    "    unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_audio_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d_audio\"])\n",
    "    unet = ConfigObject(unet_cfg[\"openai_unet_codi\"])\n",
    "\n",
    "    # CLIP\n",
    "    clip_cfg = load_yaml_config('configs/model/clip.yaml')\n",
    "    clip = ConfigObject(clip_cfg[\"clip_frozen\"])\n",
    "\n",
    "    # AutoKL\n",
    "    #autokl_cfg = load_yaml_config('configs/model/sd.yaml')\n",
    "    #autokl = ConfigObject(autokl_cfg[\"sd_autoencoder\"])\n",
    "\n",
    "    # CoDiモデルのインスタンスを作成\n",
    "    codi_cfg = load_yaml_config('configs/model/codi.yaml')\n",
    "    codi_cfg[\"codi\"][\"args\"][\"audioldm_cfg\"] = audioldm\n",
    "    #codi_cfg[\"codi\"][\"args\"][\"autokl_cfg\"] = autokl\n",
    "    codi_cfg[\"codi\"][\"args\"][\"optimus_cfg\"] = optimus\n",
    "    codi_cfg[\"codi\"][\"args\"][\"clip_cfg\"] = clip\n",
    "    codi_cfg[\"codi\"][\"args\"][\"clap_cfg\"] = clap\n",
    "    codi_cfg[\"codi\"][\"args\"][\"unet_config\"] = unet\n",
    "    codi = ConfigObject(codi_cfg[\"codi\"])\n",
    "\n",
    "    model = get_model()(codi)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_define():\n",
    "    # AudioLDM\n",
    "    audioldm_cfg = load_yaml_config('configs/model/audioldm.yaml')\n",
    "    audioldm = ConfigObject(audioldm_cfg[\"audioldm_autoencoder\"])\n",
    "\n",
    "    # Optimus\n",
    "    optimus_cfg = load_yaml_config('configs/model/optimus.yaml')\n",
    "\n",
    "    # optimus_vaeのconfigの辞書を、オブジェクトに置き換え\n",
    "    optimus_cfg['optimus_vae']['args']['encoder'] = ConfigObject(optimus_cfg['optimus_bert_encoder'])\n",
    "    optimus_cfg['optimus_vae']['args']['encoder'].args['config'] = ConfigObject(optimus_cfg['optimus_bert_encoder']['args']['config'])\n",
    "    optimus_cfg['optimus_vae']['args']['decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder'])\n",
    "    optimus_cfg['optimus_vae']['args']['decoder'].args['config'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder']['args']['config'])\n",
    "    optimus_cfg['optimus_vae']['args']['tokenizer_encoder'] = ConfigObject(optimus_cfg['optimus_bert_tokenizer'])\n",
    "    optimus_cfg['optimus_vae']['args']['tokenizer_decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_tokenizer'])\n",
    "    optimus_cfg['optimus_vae']['args']['args'] = ConfigObject(optimus_cfg['optimus_vae']['args']['args'])\n",
    "    optimus = ConfigObject(optimus_cfg[\"optimus_vae\"])\n",
    "\n",
    "    # CLAP\n",
    "    clap_cfg = load_yaml_config('configs/model/clap.yaml')\n",
    "    clap = ConfigObject(clap_cfg[\"clap_audio\"])\n",
    "\n",
    "    # Unet\n",
    "    unet_cfg = load_yaml_config('configs/model/openai_unet.yaml')\n",
    "    unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_image_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d\"])\n",
    "    unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_text_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_0dmd\"])\n",
    "    unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_audio_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d_audio\"])\n",
    "    unet = ConfigObject(unet_cfg[\"openai_unet_codi\"])\n",
    "\n",
    "    # CLIP\n",
    "    clip_cfg = load_yaml_config('configs/model/clip.yaml')\n",
    "    clip = ConfigObject(clip_cfg[\"clip_frozen\"])\n",
    "\n",
    "    # AutoKL\n",
    "    #autokl_cfg = load_yaml_config('configs/model/sd.yaml')\n",
    "    #autokl = ConfigObject(autokl_cfg[\"sd_autoencoder\"])\n",
    "\n",
    "    # CoDiモデルのインスタンスを作成\n",
    "    model = codi.CoDi(audioldm_cfg=audioldm, optimus_cfg=optimus, clip_cfg=clip, clap_cfg=clap, unet_config=unet) #autokl_cfg=autoklを削除\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_define(x, c):\n",
    "\n",
    "    if x == \"audio\" and c == \"text\":\n",
    "        # AudioLDM\n",
    "        audioldm_cfg = load_yaml_config('configs/model/audioldm.yaml')\n",
    "        audioldm = ConfigObject(audioldm_cfg[\"audioldm_autoencoder\"])\n",
    "\n",
    "        # CLIP\n",
    "        clip_cfg = load_yaml_config('configs/model/clip.yaml')\n",
    "        clip = ConfigObject(clip_cfg[\"clip_frozen\"])\n",
    "\n",
    "        # Unet\n",
    "        unet_cfg = load_yaml_config('configs/model/openai_unet.yaml')\n",
    "        unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_audio_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d_audio\"])\n",
    "        unet = ConfigObject(unet_cfg[\"openai_unet_codi\"])\n",
    "\n",
    "        # CoDiモデルのインスタンスを作成\n",
    "        codi_cfg = load_yaml_config('configs/model/codi.yaml')\n",
    "        codi_cfg[\"codi\"][\"args\"][\"audioldm_cfg\"] = audioldm\n",
    "        codi_cfg[\"codi\"][\"args\"][\"clip_cfg\"] = clip\n",
    "        codi_cfg[\"codi\"][\"args\"][\"unet_config\"] = unet\n",
    "        codi = ConfigObject(codi_cfg[\"codi\"])\n",
    "\n",
    "        model = get_model()(codi)\n",
    "        return model\n",
    "\n",
    "    elif x == \"text\" and c == \"audio\":\n",
    "        # Optimus\n",
    "        optimus_cfg = load_yaml_config('configs/model/optimus.yaml')\n",
    "\n",
    "        # optimus_vaeのconfigの辞書を、オブジェクトに置き換え\n",
    "        optimus_cfg['optimus_vae']['args']['encoder'] = ConfigObject(optimus_cfg['optimus_bert_encoder'])\n",
    "        optimus_cfg['optimus_vae']['args']['encoder'].args['config'] = ConfigObject(optimus_cfg['optimus_bert_encoder']['args']['config'])\n",
    "        optimus_cfg['optimus_vae']['args']['decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder'])\n",
    "        optimus_cfg['optimus_vae']['args']['decoder'].args['config'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder']['args']['config'])\n",
    "        optimus_cfg['optimus_vae']['args']['tokenizer_encoder'] = ConfigObject(optimus_cfg['optimus_bert_tokenizer'])\n",
    "        optimus_cfg['optimus_vae']['args']['tokenizer_decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_tokenizer'])\n",
    "        optimus_cfg['optimus_vae']['args']['args'] = ConfigObject(optimus_cfg['optimus_vae']['args']['args'])\n",
    "        optimus = ConfigObject(optimus_cfg[\"optimus_vae\"])\n",
    "\n",
    "        # CLAP\n",
    "        clap_cfg = load_yaml_config('configs/model/clap.yaml')\n",
    "        clap = ConfigObject(clap_cfg[\"clap_audio\"])\n",
    "\n",
    "        # Unet\n",
    "        unet_cfg = load_yaml_config('configs/model/openai_unet.yaml')\n",
    "        unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_text_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_0dmd\"])\n",
    "        unet = ConfigObject(unet_cfg[\"openai_unet_codi\"])\n",
    "\n",
    "        # CoDiモデルのインスタンスを作成\n",
    "        codi_cfg = load_yaml_config('configs/model/codi.yaml')\n",
    "        codi_cfg[\"codi\"][\"args\"][\"optimus_cfg\"] = optimus\n",
    "        codi_cfg[\"codi\"][\"args\"][\"clap_cfg\"] = clap\n",
    "        codi_cfg[\"codi\"][\"args\"][\"unet_config\"] = unet\n",
    "        codi = ConfigObject(codi_cfg[\"codi\"])\n",
    "\n",
    "        model = get_model()(codi)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in eps mode\n",
      "Keeping EMAs of 1124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m236866/.conda/envs/codi/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "x = \"text\"\n",
    "c = \"audio\"\n",
    "model = model_define(x, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoDi(\n",
       "  (model): Sequential(\n",
       "    (diffusion_model): UNetModelCoDi(\n",
       "      (unet_text): UNetModel0D_MultiDim(\n",
       "        (time_embed): Sequential(\n",
       "          (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (connecters_out): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=768, out_features=640, bias=True)\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear_MultiDim(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (input_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=768, out_features=1280, bias=True)\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): None\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): None\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): None\n",
       "          (10): None\n",
       "          (11): None\n",
       "        )\n",
       "        (middle_block): TimestepEmbedSequential(\n",
       "          (0): FCBlock_MultiDim(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): FCBlock_MultiDim(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (output_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (output_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear_MultiDim(in_features=1280, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model_ema): LitEma()\n",
       "  (optimus): optimus_vae(\n",
       "    (encoder): optimus_bert_connector(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "      (linear): Linear(in_features=768, out_features=1536, bias=False)\n",
       "    )\n",
       "    (decoder): optimus_gpt2_connector(\n",
       "      (transformer): GPT2Model_XX(\n",
       "        (wte): Embedding(50260, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (linear_emb): Linear(in_features=768, out_features=768, bias=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (clap): CLAPAudioEmbeddingClassifierFreev2(\n",
       "    (model): CLAP(\n",
       "      (audio_branch): HTSAT_Swin_Transformer(\n",
       "        (spec_augmenter): SpecAugmentation(\n",
       "          (time_dropper): DropStripes()\n",
       "          (freq_dropper): DropStripes()\n",
       "        )\n",
       "        (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(1, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            dim=256, input_resolution=(64, 64), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(64, 64), dim=256\n",
       "              (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicLayer(\n",
       "            dim=512, input_resolution=(32, 32), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(32, 32), dim=512\n",
       "              (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): BasicLayer(\n",
       "            dim=1024, input_resolution=(16, 16), depth=12\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (3): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (4): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (5): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (6): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (7): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (8): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (9): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (10): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (11): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(16, 16), dim=1024\n",
       "              (reduction): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): BasicLayer(\n",
       "            dim=2048, input_resolution=(8, 8), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=2048, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=2048, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=2048, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=2048, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "        (tscam_conv): Conv2d(2048, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "      )\n",
       "      (audio_transform): MLPLayers(\n",
       "        (nonlin): ReLU()\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (audio_projection): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.diffusion_model.unet_text.time_embed.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.time_embed.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.time_embed.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.time_embed.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.0.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.0.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.1.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.2.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.2.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.3.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.4.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.4.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.5.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.6.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.6.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.6.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.connecters_out.6.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.0.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.0.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.1.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.2.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.3.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.3.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.4.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.5.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.6.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.6.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.7.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.8.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.9.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.9.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.10.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_blocks.11.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.1.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.2.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.4.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.5.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.7.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.input_block_connecters_in.8.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.middle_block.2.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.0.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.1.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.2.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.3.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.4.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.5.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.6.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.7.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.8.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.9.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.10.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_blocks.11.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.3.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.4.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.5.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.6.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.7.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.8.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.9.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.10.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_text.output_block_connecters_in.11.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_text.out.0.weight requires gradient\n",
      "model.diffusion_model.unet_text.out.0.bias requires gradient\n",
      "model.diffusion_model.unet_text.out.2.weight requires gradient\n",
      "model.diffusion_model.unet_text.out.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.time_embed.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.time_embed.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.time_embed.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.time_embed.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.0.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.0.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.1.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.2.0.op.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.2.0.op.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.3.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.4.0.op.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.4.0.op.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.5.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.6.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.6.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.6.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.connecters_out.6.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.0.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.0.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.1.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.2.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.3.0.op.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.3.0.op.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.4.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.5.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.6.0.op.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.6.0.op.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.7.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.8.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.9.0.op.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.9.0.op.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.10.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_blocks.11.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.1.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.2.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.4.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.5.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.7.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.input_block_connecters_in.8.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.middle_block.2.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.0.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.1.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.1.conv.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.2.1.conv.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.3.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.4.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.2.conv.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.5.2.conv.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.6.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.7.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.2.conv.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.8.2.conv.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.9.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.10.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.in_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.in_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.in_layers.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.in_layers.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.emb_layers.1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.emb_layers.1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.out_layers.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.out_layers.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.out_layers.3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.out_layers.3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.skip_connection.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.0.skip_connection.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_blocks.11.1.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.3.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.4.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.5.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.6.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.7.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.8.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.9.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.10.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.norm.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.norm.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.proj_in.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.proj_in.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn1.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.0.proj.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.0.proj.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.ff.net.2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_q.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_k.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_v.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.attn2.to_out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm1.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm1.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm2.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm3.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.transformer_blocks.0.norm3.bias requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.proj_out.weight requires gradient\n",
      "model.diffusion_model.unet_audio.output_block_connecters_in.11.0.proj_out.bias requires gradient\n",
      "model.diffusion_model.unet_audio.out.0.weight requires gradient\n",
      "model.diffusion_model.unet_audio.out.0.bias requires gradient\n",
      "model.diffusion_model.unet_audio.out.2.weight requires gradient\n",
      "model.diffusion_model.unet_audio.out.2.bias requires gradient\n",
      "audioldm.encoder.conv_in.weight requires gradient\n",
      "audioldm.encoder.conv_in.bias requires gradient\n",
      "audioldm.encoder.down.0.block.0.norm1.weight requires gradient\n",
      "audioldm.encoder.down.0.block.0.norm1.bias requires gradient\n",
      "audioldm.encoder.down.0.block.0.conv1.weight requires gradient\n",
      "audioldm.encoder.down.0.block.0.conv1.bias requires gradient\n",
      "audioldm.encoder.down.0.block.0.norm2.weight requires gradient\n",
      "audioldm.encoder.down.0.block.0.norm2.bias requires gradient\n",
      "audioldm.encoder.down.0.block.0.conv2.weight requires gradient\n",
      "audioldm.encoder.down.0.block.0.conv2.bias requires gradient\n",
      "audioldm.encoder.down.0.block.1.norm1.weight requires gradient\n",
      "audioldm.encoder.down.0.block.1.norm1.bias requires gradient\n",
      "audioldm.encoder.down.0.block.1.conv1.weight requires gradient\n",
      "audioldm.encoder.down.0.block.1.conv1.bias requires gradient\n",
      "audioldm.encoder.down.0.block.1.norm2.weight requires gradient\n",
      "audioldm.encoder.down.0.block.1.norm2.bias requires gradient\n",
      "audioldm.encoder.down.0.block.1.conv2.weight requires gradient\n",
      "audioldm.encoder.down.0.block.1.conv2.bias requires gradient\n",
      "audioldm.encoder.down.0.downsample.conv.weight requires gradient\n",
      "audioldm.encoder.down.0.downsample.conv.bias requires gradient\n",
      "audioldm.encoder.down.1.block.0.norm1.weight requires gradient\n",
      "audioldm.encoder.down.1.block.0.norm1.bias requires gradient\n",
      "audioldm.encoder.down.1.block.0.conv1.weight requires gradient\n",
      "audioldm.encoder.down.1.block.0.conv1.bias requires gradient\n",
      "audioldm.encoder.down.1.block.0.norm2.weight requires gradient\n",
      "audioldm.encoder.down.1.block.0.norm2.bias requires gradient\n",
      "audioldm.encoder.down.1.block.0.conv2.weight requires gradient\n",
      "audioldm.encoder.down.1.block.0.conv2.bias requires gradient\n",
      "audioldm.encoder.down.1.block.0.nin_shortcut.weight requires gradient\n",
      "audioldm.encoder.down.1.block.0.nin_shortcut.bias requires gradient\n",
      "audioldm.encoder.down.1.block.1.norm1.weight requires gradient\n",
      "audioldm.encoder.down.1.block.1.norm1.bias requires gradient\n",
      "audioldm.encoder.down.1.block.1.conv1.weight requires gradient\n",
      "audioldm.encoder.down.1.block.1.conv1.bias requires gradient\n",
      "audioldm.encoder.down.1.block.1.norm2.weight requires gradient\n",
      "audioldm.encoder.down.1.block.1.norm2.bias requires gradient\n",
      "audioldm.encoder.down.1.block.1.conv2.weight requires gradient\n",
      "audioldm.encoder.down.1.block.1.conv2.bias requires gradient\n",
      "audioldm.encoder.down.1.downsample.conv.weight requires gradient\n",
      "audioldm.encoder.down.1.downsample.conv.bias requires gradient\n",
      "audioldm.encoder.down.2.block.0.norm1.weight requires gradient\n",
      "audioldm.encoder.down.2.block.0.norm1.bias requires gradient\n",
      "audioldm.encoder.down.2.block.0.conv1.weight requires gradient\n",
      "audioldm.encoder.down.2.block.0.conv1.bias requires gradient\n",
      "audioldm.encoder.down.2.block.0.norm2.weight requires gradient\n",
      "audioldm.encoder.down.2.block.0.norm2.bias requires gradient\n",
      "audioldm.encoder.down.2.block.0.conv2.weight requires gradient\n",
      "audioldm.encoder.down.2.block.0.conv2.bias requires gradient\n",
      "audioldm.encoder.down.2.block.0.nin_shortcut.weight requires gradient\n",
      "audioldm.encoder.down.2.block.0.nin_shortcut.bias requires gradient\n",
      "audioldm.encoder.down.2.block.1.norm1.weight requires gradient\n",
      "audioldm.encoder.down.2.block.1.norm1.bias requires gradient\n",
      "audioldm.encoder.down.2.block.1.conv1.weight requires gradient\n",
      "audioldm.encoder.down.2.block.1.conv1.bias requires gradient\n",
      "audioldm.encoder.down.2.block.1.norm2.weight requires gradient\n",
      "audioldm.encoder.down.2.block.1.norm2.bias requires gradient\n",
      "audioldm.encoder.down.2.block.1.conv2.weight requires gradient\n",
      "audioldm.encoder.down.2.block.1.conv2.bias requires gradient\n",
      "audioldm.encoder.mid.block_1.norm1.weight requires gradient\n",
      "audioldm.encoder.mid.block_1.norm1.bias requires gradient\n",
      "audioldm.encoder.mid.block_1.conv1.weight requires gradient\n",
      "audioldm.encoder.mid.block_1.conv1.bias requires gradient\n",
      "audioldm.encoder.mid.block_1.norm2.weight requires gradient\n",
      "audioldm.encoder.mid.block_1.norm2.bias requires gradient\n",
      "audioldm.encoder.mid.block_1.conv2.weight requires gradient\n",
      "audioldm.encoder.mid.block_1.conv2.bias requires gradient\n",
      "audioldm.encoder.mid.attn_1.norm.weight requires gradient\n",
      "audioldm.encoder.mid.attn_1.norm.bias requires gradient\n",
      "audioldm.encoder.mid.attn_1.q.weight requires gradient\n",
      "audioldm.encoder.mid.attn_1.q.bias requires gradient\n",
      "audioldm.encoder.mid.attn_1.k.weight requires gradient\n",
      "audioldm.encoder.mid.attn_1.k.bias requires gradient\n",
      "audioldm.encoder.mid.attn_1.v.weight requires gradient\n",
      "audioldm.encoder.mid.attn_1.v.bias requires gradient\n",
      "audioldm.encoder.mid.attn_1.proj_out.weight requires gradient\n",
      "audioldm.encoder.mid.attn_1.proj_out.bias requires gradient\n",
      "audioldm.encoder.mid.block_2.norm1.weight requires gradient\n",
      "audioldm.encoder.mid.block_2.norm1.bias requires gradient\n",
      "audioldm.encoder.mid.block_2.conv1.weight requires gradient\n",
      "audioldm.encoder.mid.block_2.conv1.bias requires gradient\n",
      "audioldm.encoder.mid.block_2.norm2.weight requires gradient\n",
      "audioldm.encoder.mid.block_2.norm2.bias requires gradient\n",
      "audioldm.encoder.mid.block_2.conv2.weight requires gradient\n",
      "audioldm.encoder.mid.block_2.conv2.bias requires gradient\n",
      "audioldm.encoder.norm_out.weight requires gradient\n",
      "audioldm.encoder.norm_out.bias requires gradient\n",
      "audioldm.encoder.conv_out.weight requires gradient\n",
      "audioldm.encoder.conv_out.bias requires gradient\n",
      "audioldm.decoder.conv_in.weight requires gradient\n",
      "audioldm.decoder.conv_in.bias requires gradient\n",
      "audioldm.decoder.mid.block_1.norm1.weight requires gradient\n",
      "audioldm.decoder.mid.block_1.norm1.bias requires gradient\n",
      "audioldm.decoder.mid.block_1.conv1.weight requires gradient\n",
      "audioldm.decoder.mid.block_1.conv1.bias requires gradient\n",
      "audioldm.decoder.mid.block_1.norm2.weight requires gradient\n",
      "audioldm.decoder.mid.block_1.norm2.bias requires gradient\n",
      "audioldm.decoder.mid.block_1.conv2.weight requires gradient\n",
      "audioldm.decoder.mid.block_1.conv2.bias requires gradient\n",
      "audioldm.decoder.mid.attn_1.norm.weight requires gradient\n",
      "audioldm.decoder.mid.attn_1.norm.bias requires gradient\n",
      "audioldm.decoder.mid.attn_1.q.weight requires gradient\n",
      "audioldm.decoder.mid.attn_1.q.bias requires gradient\n",
      "audioldm.decoder.mid.attn_1.k.weight requires gradient\n",
      "audioldm.decoder.mid.attn_1.k.bias requires gradient\n",
      "audioldm.decoder.mid.attn_1.v.weight requires gradient\n",
      "audioldm.decoder.mid.attn_1.v.bias requires gradient\n",
      "audioldm.decoder.mid.attn_1.proj_out.weight requires gradient\n",
      "audioldm.decoder.mid.attn_1.proj_out.bias requires gradient\n",
      "audioldm.decoder.mid.block_2.norm1.weight requires gradient\n",
      "audioldm.decoder.mid.block_2.norm1.bias requires gradient\n",
      "audioldm.decoder.mid.block_2.conv1.weight requires gradient\n",
      "audioldm.decoder.mid.block_2.conv1.bias requires gradient\n",
      "audioldm.decoder.mid.block_2.norm2.weight requires gradient\n",
      "audioldm.decoder.mid.block_2.norm2.bias requires gradient\n",
      "audioldm.decoder.mid.block_2.conv2.weight requires gradient\n",
      "audioldm.decoder.mid.block_2.conv2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.0.norm1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.0.norm1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.0.conv1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.0.conv1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.0.norm2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.0.norm2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.0.conv2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.0.conv2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.0.nin_shortcut.weight requires gradient\n",
      "audioldm.decoder.up.0.block.0.nin_shortcut.bias requires gradient\n",
      "audioldm.decoder.up.0.block.1.norm1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.1.norm1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.1.conv1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.1.conv1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.1.norm2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.1.norm2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.1.conv2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.1.conv2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.2.norm1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.2.norm1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.2.conv1.weight requires gradient\n",
      "audioldm.decoder.up.0.block.2.conv1.bias requires gradient\n",
      "audioldm.decoder.up.0.block.2.norm2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.2.norm2.bias requires gradient\n",
      "audioldm.decoder.up.0.block.2.conv2.weight requires gradient\n",
      "audioldm.decoder.up.0.block.2.conv2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.0.norm1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.0.norm1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.0.conv1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.0.conv1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.0.norm2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.0.norm2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.0.conv2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.0.conv2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.0.nin_shortcut.weight requires gradient\n",
      "audioldm.decoder.up.1.block.0.nin_shortcut.bias requires gradient\n",
      "audioldm.decoder.up.1.block.1.norm1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.1.norm1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.1.conv1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.1.conv1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.1.norm2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.1.norm2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.1.conv2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.1.conv2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.2.norm1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.2.norm1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.2.conv1.weight requires gradient\n",
      "audioldm.decoder.up.1.block.2.conv1.bias requires gradient\n",
      "audioldm.decoder.up.1.block.2.norm2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.2.norm2.bias requires gradient\n",
      "audioldm.decoder.up.1.block.2.conv2.weight requires gradient\n",
      "audioldm.decoder.up.1.block.2.conv2.bias requires gradient\n",
      "audioldm.decoder.up.1.upsample.conv.weight requires gradient\n",
      "audioldm.decoder.up.1.upsample.conv.bias requires gradient\n",
      "audioldm.decoder.up.2.block.0.norm1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.0.norm1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.0.conv1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.0.conv1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.0.norm2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.0.norm2.bias requires gradient\n",
      "audioldm.decoder.up.2.block.0.conv2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.0.conv2.bias requires gradient\n",
      "audioldm.decoder.up.2.block.1.norm1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.1.norm1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.1.conv1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.1.conv1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.1.norm2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.1.norm2.bias requires gradient\n",
      "audioldm.decoder.up.2.block.1.conv2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.1.conv2.bias requires gradient\n",
      "audioldm.decoder.up.2.block.2.norm1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.2.norm1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.2.conv1.weight requires gradient\n",
      "audioldm.decoder.up.2.block.2.conv1.bias requires gradient\n",
      "audioldm.decoder.up.2.block.2.norm2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.2.norm2.bias requires gradient\n",
      "audioldm.decoder.up.2.block.2.conv2.weight requires gradient\n",
      "audioldm.decoder.up.2.block.2.conv2.bias requires gradient\n",
      "audioldm.decoder.up.2.upsample.conv.weight requires gradient\n",
      "audioldm.decoder.up.2.upsample.conv.bias requires gradient\n",
      "audioldm.decoder.norm_out.weight requires gradient\n",
      "audioldm.decoder.norm_out.bias requires gradient\n",
      "audioldm.decoder.conv_out.weight requires gradient\n",
      "audioldm.decoder.conv_out.bias requires gradient\n",
      "audioldm.quant_conv.weight requires gradient\n",
      "audioldm.quant_conv.bias requires gradient\n",
      "audioldm.post_quant_conv.weight requires gradient\n",
      "audioldm.post_quant_conv.bias requires gradient\n",
      "audioldm.vocoder.conv_pre.bias requires gradient\n",
      "audioldm.vocoder.conv_pre.weight requires gradient\n",
      "audioldm.vocoder.ups.0.bias requires gradient\n",
      "audioldm.vocoder.ups.0.weight requires gradient\n",
      "audioldm.vocoder.ups.1.bias requires gradient\n",
      "audioldm.vocoder.ups.1.weight requires gradient\n",
      "audioldm.vocoder.ups.2.bias requires gradient\n",
      "audioldm.vocoder.ups.2.weight requires gradient\n",
      "audioldm.vocoder.ups.3.bias requires gradient\n",
      "audioldm.vocoder.ups.3.weight requires gradient\n",
      "audioldm.vocoder.ups.4.bias requires gradient\n",
      "audioldm.vocoder.ups.4.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.0.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.1.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.2.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.3.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.4.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.5.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.6.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.7.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.8.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.9.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.10.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.11.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.12.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.13.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs1.2.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.0.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.0.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.1.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.1.weight requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.2.bias requires gradient\n",
      "audioldm.vocoder.resblocks.14.convs2.2.weight requires gradient\n",
      "audioldm.vocoder.conv_post.bias requires gradient\n",
      "audioldm.vocoder.conv_post.weight requires gradient\n",
      "optimus.encoder.embeddings.word_embeddings.weight requires gradient\n",
      "optimus.encoder.embeddings.position_embeddings.weight requires gradient\n",
      "optimus.encoder.embeddings.token_type_embeddings.weight requires gradient\n",
      "optimus.encoder.embeddings.LayerNorm.weight requires gradient\n",
      "optimus.encoder.embeddings.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.0.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.0.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.1.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.1.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.2.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.2.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.3.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.3.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.4.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.4.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.5.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.5.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.6.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.6.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.7.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.7.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.8.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.8.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.9.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.9.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.10.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.10.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.query.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.query.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.key.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.key.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.value.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.self.value.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.attention.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.intermediate.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.intermediate.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.output.dense.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.output.dense.bias requires gradient\n",
      "optimus.encoder.encoder.layer.11.output.LayerNorm.weight requires gradient\n",
      "optimus.encoder.encoder.layer.11.output.LayerNorm.bias requires gradient\n",
      "optimus.encoder.pooler.dense.weight requires gradient\n",
      "optimus.encoder.pooler.dense.bias requires gradient\n",
      "optimus.encoder.linear.weight requires gradient\n",
      "optimus.decoder.transformer.wte.weight requires gradient\n",
      "optimus.decoder.transformer.wpe.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.0.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.0.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.0.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.0.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.0.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.0.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.1.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.1.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.2.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.2.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.3.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.3.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.4.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.4.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.5.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.5.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.6.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.6.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.7.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.7.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.8.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.8.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.9.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.9.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.10.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.10.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.ln_1.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.ln_1.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.attn.c_attn.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.attn.c_attn.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.attn.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.attn.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.ln_2.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.ln_2.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.mlp.c_fc.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.mlp.c_fc.bias requires gradient\n",
      "optimus.decoder.transformer.h.11.mlp.c_proj.weight requires gradient\n",
      "optimus.decoder.transformer.h.11.mlp.c_proj.bias requires gradient\n",
      "optimus.decoder.transformer.ln_f.weight requires gradient\n",
      "optimus.decoder.transformer.ln_f.bias requires gradient\n",
      "optimus.decoder.transformer.linear.weight requires gradient\n",
      "optimus.decoder.transformer.linear_emb.weight requires gradient\n",
      "clap.model.audio_branch.bn0.weight requires gradient\n",
      "clap.model.audio_branch.bn0.bias requires gradient\n",
      "clap.model.audio_branch.patch_embed.proj.weight requires gradient\n",
      "clap.model.audio_branch.patch_embed.proj.bias requires gradient\n",
      "clap.model.audio_branch.patch_embed.norm.weight requires gradient\n",
      "clap.model.audio_branch.patch_embed.norm.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.0.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.blocks.1.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.0.downsample.reduction.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.downsample.norm.weight requires gradient\n",
      "clap.model.audio_branch.layers.0.downsample.norm.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.0.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.blocks.1.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.1.downsample.reduction.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.downsample.norm.weight requires gradient\n",
      "clap.model.audio_branch.layers.1.downsample.norm.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.0.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.1.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.2.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.3.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.4.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.5.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.6.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.7.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.8.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.9.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.10.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.blocks.11.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.2.downsample.reduction.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.downsample.norm.weight requires gradient\n",
      "clap.model.audio_branch.layers.2.downsample.norm.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.0.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.norm1.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.norm1.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.attn.relative_position_bias_table requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.attn.qkv.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.attn.qkv.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.attn.proj.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.attn.proj.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.norm2.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.norm2.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.mlp.fc1.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.mlp.fc1.bias requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.mlp.fc2.weight requires gradient\n",
      "clap.model.audio_branch.layers.3.blocks.1.mlp.fc2.bias requires gradient\n",
      "clap.model.audio_branch.norm.weight requires gradient\n",
      "clap.model.audio_branch.norm.bias requires gradient\n",
      "clap.model.audio_branch.tscam_conv.weight requires gradient\n",
      "clap.model.audio_branch.tscam_conv.bias requires gradient\n",
      "clap.model.audio_branch.head.weight requires gradient\n",
      "clap.model.audio_branch.head.bias requires gradient\n",
      "clap.model.audio_transform.sequential.0.weight requires gradient\n",
      "clap.model.audio_transform.sequential.0.bias requires gradient\n",
      "clap.model.audio_transform.sequential.3.weight requires gradient\n",
      "clap.model.audio_transform.sequential.3.bias requires gradient\n",
      "clap.model.audio_projection.0.weight requires gradient\n",
      "clap.model.audio_projection.0.bias requires gradient\n",
      "clap.model.audio_projection.2.weight requires gradient\n",
      "clap.model.audio_projection.2.bias requires gradient\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} requires gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f49c10c1120>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoDi(\n",
       "  (model): Sequential(\n",
       "    (diffusion_model): UNetModelCoDi(\n",
       "      (unet_text): UNetModel0D_MultiDim(\n",
       "        (time_embed): Sequential(\n",
       "          (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (connecters_out): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=768, out_features=640, bias=True)\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear_MultiDim(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (input_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=768, out_features=1280, bias=True)\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): None\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): None\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): None\n",
       "          (10): None\n",
       "          (11): None\n",
       "        )\n",
       "        (middle_block): TimestepEmbedSequential(\n",
       "          (0): FCBlock_MultiDim(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): FCBlock_MultiDim(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (output_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): FCBlock_MultiDim(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (output_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear_MultiDim(in_features=1280, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (unet_audio): UNetModel2D(\n",
       "        (time_embed): Sequential(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (connecters_out): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Conv2d(8, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): Downsample(\n",
       "              (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): Downsample(\n",
       "              (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(768, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (input_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): Conv2d(8, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): Downsample(\n",
       "              (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): Downsample(\n",
       "              (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): Downsample(\n",
       "              (op): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): None\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): None\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): None\n",
       "          (10): None\n",
       "          (11): None\n",
       "        )\n",
       "        (middle_block): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (output_blocks): ModuleList(\n",
       "          (0): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): Upsample(\n",
       "              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (upsample): UpsampleDeterministic()\n",
       "            )\n",
       "          )\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1152, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1152, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Upsample(\n",
       "              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (upsample): UpsampleDeterministic()\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1152, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(576, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Upsample(\n",
       "              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (upsample): UpsampleDeterministic()\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (output_block_connecters_in): ModuleList(\n",
       "          (0): None\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (5): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (7): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (8): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (9): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (10): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (11): TimestepEmbedSequential(\n",
       "            (0): SpatialTransformer(\n",
       "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "              (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (transformer_blocks): ModuleList(\n",
       "                (0): BasicTransformerBlock(\n",
       "                  (attn1): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (ff): FeedForward(\n",
       "                    (net): Sequential(\n",
       "                      (0): GEGLU(\n",
       "                        (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                      )\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                      (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (attn2): CrossAttention(\n",
       "                    (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                    (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                    (to_out): Sequential(\n",
       "                      (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (1): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model_ema): LitEma()\n",
       "  (audioldm): AudioAutoencoderKL(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (quant_conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (vocoder): Generator(\n",
       "      (conv_pre): Conv1d(64, 1024, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ConvTranspose1d(1024, 512, kernel_size=(16,), stride=(5,), padding=(5,))\n",
       "        (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "        (2): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "        (3): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (4): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (12): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (13): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (14): ResBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    )\n",
       "    (fn_STFT): TacotronSTFT(\n",
       "      (stft_fn): STFT()\n",
       "    )\n",
       "  )\n",
       "  (optimus): optimus_vae(\n",
       "    (encoder): optimus_bert_connector(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "      (linear): Linear(in_features=768, out_features=1536, bias=False)\n",
       "    )\n",
       "    (decoder): optimus_gpt2_connector(\n",
       "      (transformer): GPT2Model_XX(\n",
       "        (wte): Embedding(50260, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (linear_emb): Linear(in_features=768, out_features=768, bias=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (clip): FrozenCLIP(\n",
       "    (model): CLIPModel(\n",
       "      (text_model): CLIPTextTransformer(\n",
       "        (embeddings): CLIPTextEmbeddings(\n",
       "          (token_embedding): Embedding(49408, 768)\n",
       "          (position_embedding): Embedding(77, 768)\n",
       "        )\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (10): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (11): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (vision_model): CLIPVisionTransformer(\n",
       "        (embeddings): CLIPVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "          (position_embedding): Embedding(257, 1024)\n",
       "        )\n",
       "        (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (4): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (5): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (6): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (7): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (8): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (9): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (10): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (11): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (12): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (13): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (14): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (15): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (16): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (17): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (18): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (19): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (20): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (21): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (22): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (23): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (temporal_self_attn): SpatioTemporalAttention(\n",
       "                (temporal_attn): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                  (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                )\n",
       "                (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "                  (net): ModuleList(\n",
       "                    (0): Sequential(\n",
       "                      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (1): Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                      (1): SiLU()\n",
       "                    )\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (proj_in): Sequential(\n",
       "                    (0): Conv1d(1024, 5460, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                    (1): GEGLU()\n",
       "                  )\n",
       "                  (proj_out): Sequential(\n",
       "                    (0): ChanLayerNorm()\n",
       "                    (1): Conv1d(2730, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (visual_projection): Linear(in_features=1024, out_features=768, bias=False)\n",
       "      (text_projection): Linear(in_features=768, out_features=768, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (clap): CLAPAudioEmbeddingClassifierFreev2(\n",
       "    (model): CLAP(\n",
       "      (audio_branch): HTSAT_Swin_Transformer(\n",
       "        (spec_augmenter): SpecAugmentation(\n",
       "          (time_dropper): DropStripes()\n",
       "          (freq_dropper): DropStripes()\n",
       "        )\n",
       "        (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(1, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            dim=256, input_resolution=(64, 64), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=256, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=256, window_size=(8, 8), num_heads=4\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(64, 64), dim=256\n",
       "              (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicLayer(\n",
       "            dim=512, input_resolution=(32, 32), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=512, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=512, window_size=(8, 8), num_heads=8\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(32, 32), dim=512\n",
       "              (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): BasicLayer(\n",
       "            dim=1024, input_resolution=(16, 16), depth=12\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (3): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (4): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (5): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (6): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (7): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (8): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (9): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (10): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (11): SwinTransformerBlock(\n",
       "                dim=1024, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=1024, window_size=(8, 8), num_heads=16\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMerging(\n",
       "              input_resolution=(16, 16), dim=1024\n",
       "              (reduction): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): BasicLayer(\n",
       "            dim=2048, input_resolution=(8, 8), depth=2\n",
       "            (blocks): ModuleList(\n",
       "              (0): SwinTransformerBlock(\n",
       "                dim=2048, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=2048, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinTransformerBlock(\n",
       "                dim=2048, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "                (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  dim=2048, window_size=(8, 8), num_heads=32\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath()\n",
       "                (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                  (act): GELU(approximate=none)\n",
       "                  (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "        (tscam_conv): Conv2d(2048, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "      )\n",
       "      (audio_transform): MLPLayers(\n",
       "        (nonlin): ReLU()\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (audio_projection): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.model.diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModelCoDi(\n",
       "  (unet_image): UNetModel2D(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (connecters_out): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(4, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): None\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): None\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): None\n",
       "      (10): None\n",
       "      (11): None\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ModuleList(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatioTemporalAttention(\n",
       "          (frameshiftblock): ResBlockFrameShift(\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (temporal_attn): Attention(\n",
       "            (norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "            (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "            (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "          )\n",
       "          (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "            (net): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                (1): SiLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): SiLU()\n",
       "              )\n",
       "              (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (proj_in): Sequential(\n",
       "              (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (1): GEGLU()\n",
       "            )\n",
       "            (proj_out): Sequential(\n",
       "              (0): ChanLayerNorm()\n",
       "              (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatioTemporalAttention(\n",
       "          (frameshiftblock): ResBlockFrameShift(\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (temporal_attn): Attention(\n",
       "            (norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "            (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "            (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "          )\n",
       "          (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "            (net): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                (1): SiLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): SiLU()\n",
       "              )\n",
       "              (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (proj_in): Sequential(\n",
       "              (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (1): GEGLU()\n",
       "            )\n",
       "            (proj_out): Sequential(\n",
       "              (0): ChanLayerNorm()\n",
       "              (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=1280, out_features=2560, bias=False)\n",
       "              (to_kv): Linear(in_features=1280, out_features=5120, bias=False)\n",
       "              (to_out): Linear(in_features=2560, out_features=1280, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=640, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(1280, 6826, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(3413, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=640, out_features=1280, bias=False)\n",
       "              (to_kv): Linear(in_features=640, out_features=2560, bias=False)\n",
       "              (to_out): Linear(in_features=1280, out_features=640, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=320, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(640, 3412, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(1706, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatioTemporalAttention(\n",
       "            (frameshiftblock): ResBlockFrameShift(\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (temporal_attn): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=320, out_features=640, bias=False)\n",
       "              (to_kv): Linear(in_features=320, out_features=1280, bias=False)\n",
       "              (to_out): Linear(in_features=640, out_features=320, bias=False)\n",
       "            )\n",
       "            (temporal_rel_pos_bias): ContinuousPositionBias(\n",
       "              (net): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (1): SiLU()\n",
       "                )\n",
       "                (2): Linear(in_features=160, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (proj_in): Sequential(\n",
       "                (0): Conv3d(320, 1706, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "                (1): GEGLU()\n",
       "              )\n",
       "              (proj_out): Sequential(\n",
       "                (0): ChanLayerNorm()\n",
       "                (1): Conv3d(853, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): None\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (unet_text): UNetModel0D_MultiDim(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (connecters_out): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=768, out_features=640, bias=True)\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear_MultiDim(in_features=5120, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=768, out_features=1280, bias=True)\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1280, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): None\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): None\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): None\n",
       "      (10): None\n",
       "      (11): None\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): FCBlock_MultiDim(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): FCBlock_MultiDim(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 10240, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(10240, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(7680, 5120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Linear_MultiDim(in_features=5120, out_features=5120, bias=True)\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 7680, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(7680, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(5120, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(2560, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(3840, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Linear_MultiDim(in_features=2560, out_features=2560, bias=True)\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3840, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(3840, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): FCBlock_MultiDim(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): None\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear_MultiDim(in_features=1280, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (unet_audio): UNetModel2D(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (connecters_out): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(8, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(768, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(8, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): None\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): None\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): None\n",
       "      (10): None\n",
       "      (11): None\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1152, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1152, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1152, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(576, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (upsample): UpsampleDeterministic()\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_block_connecters_in): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): None\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(192, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.unet_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel2D(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (connecters_out): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(8, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(768, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(8, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (input_block_connecters_in): ModuleList(\n",
       "    (0): None\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): None\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): None\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): None\n",
       "    (10): None\n",
       "    (11): None\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (upsample): UpsampleDeterministic()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1152, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1152, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (upsample): UpsampleDeterministic()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1152, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(576, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=384, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (upsample): UpsampleDeterministic()\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 576, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_block_connecters_in): ModuleList(\n",
       "    (0): None\n",
       "    (1): None\n",
       "    (2): None\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 768, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=768, out_features=6144, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=384, out_features=3072, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=384, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=192, out_features=1536, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=192, out_features=192, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=192, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(192, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.onnx\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      2\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodi.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/__init__.py:350\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mExports a model into ONNX format. If ``model`` is not a\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    model to the file ``f`` even if this is raised.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/utils.py:163\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    146\u001b[0m     model,\n\u001b[1;32m    147\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     export_modules_as_functions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m ):\n\u001b[0;32m--> 163\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/utils.py:1074\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1072\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1074\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1089\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1090\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/utils.py:727\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    724\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m    726\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m--> 727\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/utils.py:602\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    604\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/onnx/utils.py:517\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_trace_and_get_graph_from_model\u001b[39m(model, args):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# A basic sanity check: make sure the state_dict keys are the same\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;66;03m# before and after running the model.  Fail fast!\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     orig_state_dict_keys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m--> 517\u001b[0m     trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     warn_on_static_input_change(inputs_states)\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig_state_dict_keys \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/jit/_trace.py:1175\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1174\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1175\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/jit/_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 127\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/jit/_trace.py:118\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    117\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 118\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    120\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/nn/modules/module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/diffusion_unet.py:772\u001b[0m, in \u001b[0;36mUNetModel2D.forward\u001b[0;34m(self, x, timesteps, context)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    771\u001b[0m     hs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 772\u001b[0m     t_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtimestep_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed(t_emb)\n\u001b[1;32m    775\u001b[0m     h \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/modules_conv.py:69\u001b[0m, in \u001b[0;36mtimestep_embedding\u001b[0;34m(timesteps, dim, max_period, repeat_only)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repeat_only:\n\u001b[1;32m     66\u001b[0m     half \u001b[38;5;241m=\u001b[39m dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     67\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(max_period) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39mhalf, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m half\n\u001b[0;32m---> 69\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m)\n\u001b[1;32m     70\u001b[0m     args \u001b[38;5;241m=\u001b[39m timesteps[:, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m freqs[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     71\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mcos(args), torch\u001b[38;5;241m.\u001b[39msin(args)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 8, 256, 16)\n",
    "output_file = \"codi.onnx\"\n",
    "torch.onnx.export(model, dummy_input, output_file, verbose=True, opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.diffusion_model()を試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicCaps(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, model, x, c, transform=None):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.model = model\n",
    "        self.x = x\n",
    "        self.c = c\n",
    "        \n",
    "        # CSVファイルを読み込む\n",
    "        all_data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # 音声ファイルが存在するかどうかを確認し、存在するデータのみをリストに追加\n",
    "        for idx, row in all_data.iterrows():\n",
    "            audio_path = os.path.join(self.audio_dir, f\"{row['ytid']}.wav\")\n",
    "            if os.path.exists(audio_path):\n",
    "                self.data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        caption = row['caption'] # 生テキスト\n",
    "        audio_path = os.path.join(self.audio_dir, f\"{row['ytid']}.wav\")    \n",
    "        waveform = torchaudio.load(audio_path) # 生波形データ（Tensor）\n",
    "\n",
    "        if self.x == \"audio\" and self.c == \"text\":\n",
    "            mel_latent = self.model.audioldm_encode(waveform[0]).detach() # メルスペクトログラム（Tensor）の潜在表現に変換\n",
    "            text_emb = self.model.clip_encode_text([caption]).detach()\n",
    "            return mel_latent, text_emb # data, condition\n",
    "        elif self.x == \"text\" and self.c == \"audio\":\n",
    "            text_latent = self.model.optimus_encode([caption]).detach()\n",
    "            audio_emb = self.model.clap_encode_audio(waveform[0]).detach()\n",
    "            return text_latent, audio_emb # data, condition\n",
    "\n",
    "x = \"audio\"\n",
    "c = \"text\"\n",
    "\n",
    "# データセット\n",
    "dataset = MusicCaps(csv_file='/raid/m236866/md-mt/datasets/musiccaps/musiccaps-public.csv',\n",
    "                            audio_dir='/raid/m236866/md-mt/datasets/musiccaps/musiccaps_30', model=model, x=x, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mMusicCaps.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m waveform \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path) \u001b[38;5;66;03m# 生波形データ（Tensor）\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     mel_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudioldm_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;66;03m# メルスペクトログラム（Tensor）の潜在表現に変換\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     text_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mclip_encode_text([caption])\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_latent, text_emb \u001b[38;5;66;03m# data, condition\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/codi.py:104\u001b[0m, in \u001b[0;36mCoDi.audioldm_encode\u001b[0;34m(self, audio, time)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maudioldm_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, audio, time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m):\n\u001b[0;32m--> 104\u001b[0m     encoder_posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudioldm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     z \u001b[38;5;241m=\u001b[39m encoder_posterior\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mto(audio\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_scale_factor\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/vae/audioldm.py:56\u001b[0m, in \u001b[0;36mAudioAutoencoderKL.encode\u001b[0;34m(self, x, time)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m):\n\u001b[1;32m     55\u001b[0m     temp_dtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mwav_to_fbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m102.4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_STFT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_STFT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(temp_dtype)\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_split_subband(x)\n\u001b[1;32m     60\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/vae/audioldm_modules/audio/tools.py:67\u001b[0m, in \u001b[0;36mwav_to_fbank\u001b[0;34m(waveform, target_length, fn_STFT)\u001b[0m\n\u001b[1;32m     65\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m waveform_i \u001b[38;5;129;01min\u001b[39;00m waveform:\n\u001b[0;32m---> 67\u001b[0m     fbank, log_magnitudes_stft, energy \u001b[38;5;241m=\u001b[39m \u001b[43mget_mel_from_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_STFT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     fbank \u001b[38;5;241m=\u001b[39m fbank[:, :target_length]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     69\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(fbank)\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/vae/audioldm_modules/audio/tools.py:10\u001b[0m, in \u001b[0;36mget_mel_from_wav\u001b[0;34m(audio, _stft)\u001b[0m\n\u001b[1;32m      8\u001b[0m audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclip(audio\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(audio, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m---> 10\u001b[0m melspec, log_magnitudes_stft, energy \u001b[38;5;241m=\u001b[39m \u001b[43m_stft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m melspec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(melspec, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m log_magnitudes_stft \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     torch\u001b[38;5;241m.\u001b[39msqueeze(log_magnitudes_stft, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/vae/audioldm_modules/audio/stft.py:172\u001b[0m, in \u001b[0;36mTacotronSTFT.mel_spectrogram\u001b[0;34m(self, y, normalize_fun)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmin(y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, torch\u001b[38;5;241m.\u001b[39mmin(y\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, torch\u001b[38;5;241m.\u001b[39mmax(y\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 172\u001b[0m magnitudes, phases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstft_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m magnitudes \u001b[38;5;241m=\u001b[39m magnitudes\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    174\u001b[0m mel_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmel_basis\u001b[38;5;241m.\u001b[39mto(magnitudes), magnitudes)\n",
      "File \u001b[0;32m/raid/m236866/md-mt2/core/models/latent_diffusion/vae/audioldm_modules/audio/stft.py:67\u001b[0m, in \u001b[0;36mSTFT.transform\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m input_data \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     61\u001b[0m     input_data\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     62\u001b[0m     (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     63\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m input_data \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m forward_transform \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     74\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m real_part \u001b[38;5;241m=\u001b[39m forward_transform[:, :cutoff, :]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(0, model.num_timesteps, (x[0].shape[0],), device=x[0].device).long()\n",
    "\n",
    "\n",
    "model.model.diffusion_model(x_noisy, t, cond, xtype, ctype, u=None, return_algined_latents=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = codi.optimus_encode([\"hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.randint(0, codi.num_timesteps, (x[0].shape[0],), device=x[0].device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = None\n",
    "noise = [torch.randn_like(x_start_i) for x_start_i in x] if noise is None else noise\n",
    "x_noisy = [codi.q_sample(x_start=x_start_i, t=t, noise=noise_i) for x_start_i, noise_i in zip(x, noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1894,  1.3658, -0.6403,  0.9748,  0.0898, -0.7792,  0.0979, -0.9063,\n",
       "          0.5764,  0.7412,  0.6682,  0.1002, -0.3077, -0.0954,  0.5905,  0.7162,\n",
       "          0.2882, -1.3121,  0.4856, -1.1572, -0.3025, -0.7747,  0.3022, -0.0156,\n",
       "          0.3011,  1.2997, -0.1633, -0.9710, -0.2664, -0.4748,  0.2857,  0.1940,\n",
       "          2.2678,  0.9325, -0.4579,  0.5283, -1.6967, -1.0400, -0.8210, -0.2837,\n",
       "         -0.6577,  0.2362,  0.2527,  0.6037,  1.2061, -1.7121, -0.4699, -0.1443,\n",
       "         -1.2653,  0.2267, -0.3568,  1.0388, -0.1290, -1.0382,  1.4018, -0.4542,\n",
       "          0.0713,  0.1117, -0.7701,  0.2701, -0.4876,  0.2708,  0.1550,  0.7127,\n",
       "         -2.4099,  0.4508, -1.1212,  0.0443, -2.3184, -0.7415,  0.6727, -0.4572,\n",
       "         -0.0061,  0.8455, -0.6623,  0.9933,  0.1541,  1.7224, -1.2723, -1.0646,\n",
       "         -1.1300, -0.6050, -0.4717,  1.8231,  2.0241, -0.6310, -0.2439, -1.1119,\n",
       "          1.2734,  1.1327, -0.6193, -0.7319, -0.1388, -1.3069,  0.3155,  0.2693,\n",
       "         -0.5731, -0.0317, -0.2033,  1.4762, -0.8632,  0.6970, -0.4401, -0.0698,\n",
       "         -0.1996, -0.1280, -0.2976, -0.0353, -0.9535,  1.0667,  0.3315, -0.3732,\n",
       "         -1.1375, -1.3938,  0.9856,  0.6593,  2.0836,  1.1666, -0.5433,  0.2640,\n",
       "          0.8218,  0.4716,  1.1206,  0.4466, -1.1992, -0.8389, -1.0515,  0.5813,\n",
       "         -0.7010,  0.9131, -1.2169, -0.1671, -0.8799,  1.2393,  0.0053,  1.0959,\n",
       "          0.2440, -1.3390,  1.3876, -0.1631,  1.2370, -0.0502, -0.6449,  0.2832,\n",
       "         -0.2833, -0.1761, -2.9175,  0.4242,  0.3618, -0.1303, -0.1966, -0.7977,\n",
       "         -2.2531, -0.6633,  0.1340,  3.0445, -1.3294,  0.5587,  1.8956, -0.4740,\n",
       "         -0.7909,  1.0724, -0.0364, -1.8007,  2.8665,  0.0044, -1.1264,  0.4556,\n",
       "          1.5790,  0.3291,  1.1726, -0.6485, -0.1082,  0.2616,  0.7795,  0.1159,\n",
       "         -0.7513, -0.6939, -0.0677,  2.5417,  1.2846, -0.5395,  0.9874,  0.3846,\n",
       "          0.2637,  1.1173,  0.5136, -0.7863,  0.7845,  0.9481,  0.1009, -1.1786,\n",
       "         -0.2592, -1.0058,  0.0302,  0.6875, -1.8532, -1.0209, -0.4840, -1.6230,\n",
       "          1.0946,  1.4009, -0.7051,  0.7560,  2.6616, -1.0139,  1.0673,  0.4873,\n",
       "          2.4478,  0.3165, -0.1988, -0.6375,  0.3580, -0.8331, -0.5974, -0.9333,\n",
       "          0.1096,  1.2575,  1.2103, -1.6413,  0.4509, -0.7858,  2.3806,  0.6628,\n",
       "          1.0017, -0.0591, -0.8797,  0.0773, -1.2636,  1.9290,  0.9353,  1.6940,\n",
       "          1.8609,  1.1401, -1.7130, -1.8582,  0.6488,  0.8499, -0.8260,  0.6990,\n",
       "          1.0295, -0.1813,  2.0121,  0.3505, -1.0734, -1.0502, -0.4451,  0.3362,\n",
       "         -0.3482,  0.0899,  0.6131, -1.6933, -2.8074,  0.8155,  1.0457, -0.7055,\n",
       "         -0.4675, -0.2792, -0.7588, -1.7572, -0.6407,  0.4848,  0.2479,  0.5738,\n",
       "          1.3807,  1.8874, -0.6536, -0.4561, -0.9561, -0.6263,  0.3246,  0.3366,\n",
       "         -0.8825,  0.0480,  2.0489,  0.2316, -1.0308, -1.3514, -0.4619,  0.3622,\n",
       "         -1.5019,  0.2740,  0.6714,  0.6308,  1.9307,  0.5435, -0.6809, -0.6816,\n",
       "          0.3939, -1.2724, -0.6138, -1.6286, -0.5606, -0.5425, -1.2708, -1.3252,\n",
       "         -0.3681, -0.6995,  2.4624,  0.5918, -1.7105, -0.3199, -0.5292,  1.1368,\n",
       "         -0.5759, -0.2105,  1.5074, -0.3624, -0.2750, -0.1426,  0.8123,  0.4576,\n",
       "         -1.4186,  1.6931, -0.9210,  0.3249, -1.9744, -0.9271,  0.3117,  0.2647,\n",
       "          2.3368,  0.0463, -1.5665, -1.7888, -0.2045, -0.9282,  1.3150,  1.4817,\n",
       "         -1.2565, -2.7325, -0.4332,  2.1360, -1.6756, -0.5388, -0.5454,  0.7127,\n",
       "          0.8958,  2.2559, -1.6287,  0.9821,  0.1988, -0.5327,  0.3831, -1.0158,\n",
       "          1.4273,  0.5952, -1.0128, -0.0123,  1.2807,  2.4798,  1.2013, -1.9391,\n",
       "         -0.1958,  0.9373, -0.8577, -2.0023, -1.6165, -0.9059, -0.5190, -0.0401,\n",
       "         -0.1028,  1.3566,  0.0305, -0.3471,  0.0613, -0.0823,  0.3214,  1.5265,\n",
       "          0.9545, -0.7881,  1.1461,  1.4462, -0.0090, -0.7260, -0.0930,  1.8954,\n",
       "         -0.4212,  0.3419,  1.1730,  2.1381,  0.2589, -0.9207,  0.4693, -0.5418,\n",
       "          0.3287, -0.2710, -0.1236,  1.5900,  0.0383,  0.2393,  0.8060, -0.6359,\n",
       "         -0.7495, -0.2598, -1.0143, -1.4136,  0.3524, -0.3950, -0.3045,  0.8393,\n",
       "          0.1066, -0.0429, -0.6854, -0.0890,  0.0324,  0.9543,  1.1273,  0.2158,\n",
       "          2.4470, -1.9720,  0.1213,  1.1634,  0.7293,  0.2862, -0.2369,  0.7678,\n",
       "          0.1459,  0.0726, -0.3511, -1.0192, -0.0431, -0.5233, -0.9120, -1.3665,\n",
       "          0.8448, -0.6632, -0.3568,  1.4412,  1.2598,  0.7911,  0.7178,  1.7043,\n",
       "          0.3664, -0.2446, -1.0413,  1.4561,  0.6116,  0.2310,  2.0206,  0.3018,\n",
       "          0.7690,  1.4025, -0.2865,  1.5137,  0.3379,  0.2549,  0.3711, -0.4352,\n",
       "         -0.8325,  1.0847,  1.8360, -0.9415, -0.0956,  1.0121, -1.8477,  2.1883,\n",
       "         -1.6372,  1.0496, -1.1025, -0.6148,  0.7229,  1.7676, -0.5908,  0.8878,\n",
       "          0.8048,  0.4873,  0.8964,  0.2850,  1.4479, -1.0692,  2.0520,  0.3713,\n",
       "         -0.6349, -0.2385, -0.8239, -0.8165,  0.3722,  0.4730, -0.5788, -1.3792,\n",
       "         -0.9679, -1.7768, -0.1623, -0.5900, -1.0203, -1.5820,  0.5727,  0.0231,\n",
       "          1.5281,  0.0235, -0.3718, -0.8557, -0.2087, -0.0745,  0.0559,  0.0570,\n",
       "          0.2330,  1.5573, -2.2658,  1.3741, -2.3671, -0.0885,  0.0363, -0.3844,\n",
       "         -0.1532,  0.1947,  0.2489, -0.1860, -0.7201,  0.6049, -0.8564,  0.0196,\n",
       "         -0.0062,  0.1970, -0.4522, -1.9675, -0.8091, -2.2339,  0.6492,  0.5595,\n",
       "         -0.6864, -0.5243,  1.2345, -0.4069, -1.3553, -2.0115, -1.3549,  0.5070,\n",
       "         -0.5544, -1.7807,  0.1872, -1.2189,  1.1749,  1.8384, -0.6279, -0.3354,\n",
       "          1.1938, -0.8753, -0.8271, -0.4643,  0.9702,  0.3223,  0.0634, -0.5326,\n",
       "         -2.0137,  0.3467,  1.0612,  1.1528, -0.1686, -0.5474,  1.3635, -0.9839,\n",
       "         -0.7112,  0.1744,  0.0562, -1.5485,  0.7107,  0.7822,  1.1248,  1.1147,\n",
       "          0.7353, -0.0882, -1.5255, -0.5952,  1.0415,  0.6269, -1.1244,  2.1386,\n",
       "          1.0112,  0.8617, -1.6041, -0.3695, -0.6706,  0.5117, -0.1284,  0.2539,\n",
       "          0.0391, -0.2222,  0.2119,  0.6553, -0.1031,  0.9065,  0.5608, -1.4352,\n",
       "         -0.4496,  1.2519, -1.3496, -2.4915,  0.2677,  0.3377,  0.3205,  2.4603,\n",
       "         -0.8956,  0.0875, -0.1676,  1.2133,  1.8550, -0.8737,  0.3617, -0.2203,\n",
       "         -0.1552,  0.4581,  0.8346, -0.9273, -0.2489,  0.3292, -0.0987,  0.1751,\n",
       "         -1.7006, -0.0132,  2.8389,  0.7437, -0.7207, -1.1941,  0.7267,  0.4579,\n",
       "          0.4905,  0.5635,  0.1050, -1.7025,  2.0247, -2.0678,  1.3908,  0.2260,\n",
       "          0.5446,  0.1185,  1.7145,  0.4488, -0.5974, -0.0576, -0.1486, -1.5312,\n",
       "         -0.2988, -0.4311, -0.7726,  0.1047, -0.0589,  1.0607, -1.7028, -2.7787,\n",
       "          0.4002, -0.2388, -0.0210,  0.9351, -0.0749,  0.3345,  1.8732,  0.6256,\n",
       "         -1.9838, -1.2866,  0.5863,  0.7442, -1.3838,  2.0841,  0.3605, -1.2886,\n",
       "          0.5789,  1.9157,  0.1645, -0.1068,  0.6279, -1.7595, -0.0667, -0.1423,\n",
       "         -0.9454,  2.9542,  0.6124,  0.7563,  0.7497,  0.9392, -0.1462, -1.0563,\n",
       "          1.3210,  0.4143,  0.5908, -0.2776,  0.1816, -0.6001,  1.2960,  1.1114,\n",
       "         -0.6845,  0.5558,  1.2998, -1.4518,  0.1618, -0.7642,  0.0845,  2.4595,\n",
       "          1.4213, -1.1275,  0.3808,  0.3607, -1.3384, -1.0725,  0.0549,  0.1674,\n",
       "         -0.1279, -0.1321, -0.0310,  0.6831,  2.0182, -0.5095,  1.8491,  0.5928,\n",
       "         -0.9278,  1.9774, -1.4536, -0.2016, -0.6463,  0.6415, -0.1714,  0.3593,\n",
       "         -0.0847, -1.3848,  2.1552,  0.9953,  0.7430,  1.2545,  0.5958, -1.3499,\n",
       "         -1.0616, -1.2483, -0.1507, -0.8451,  0.0927,  0.6578, -1.6458,  1.2558,\n",
       "         -1.5918, -0.0640,  1.2184,  3.7851, -1.4234,  0.4070,  0.2040, -1.0908,\n",
       "          0.5529,  1.2226,  0.7501, -1.5473, -0.4478, -0.9544,  1.2637,  0.8215,\n",
       "          0.1824, -0.0333,  1.0548, -0.2187,  0.4550,  0.5828,  1.5060,  0.7401,\n",
       "          0.5818, -0.1220,  1.0916,  0.1573,  0.2966,  0.0956,  2.0949, -0.9292,\n",
       "         -0.3070, -1.3099,  0.5477,  0.3518,  0.0439, -1.4744, -1.6637,  1.3349]),\n",
       " tensor([-1.1429e-01, -1.4768e+00, -2.7953e-01, -1.0463e+00, -7.0490e-01,\n",
       "         -9.5222e-01,  5.0041e-01,  1.0830e-01,  1.3526e-01,  9.6969e-01,\n",
       "          4.8788e-01,  1.1032e+00, -1.2135e+00,  7.5145e-01, -6.2494e-01,\n",
       "         -1.8906e-01,  9.4566e-01, -3.1641e-01, -1.0325e+00,  9.8858e-01,\n",
       "         -1.9868e-01,  3.7275e-01, -1.4867e-01,  2.7173e-01,  1.6488e+00,\n",
       "         -6.4648e-01,  5.8297e-01,  4.1064e-01,  2.7813e+00,  1.4638e-01,\n",
       "         -9.1606e-01, -1.2077e+00,  3.4083e-02,  2.0856e-01, -1.4597e+00,\n",
       "          3.7202e-01,  7.5390e-02,  5.1765e-01, -9.7844e-01, -1.8240e+00,\n",
       "         -1.4315e+00,  1.3050e-01,  1.5223e-01,  6.8478e-01, -8.0601e-01,\n",
       "          1.4793e+00, -7.8077e-01, -1.5364e+00, -8.1964e-01,  6.1405e-02,\n",
       "         -5.9189e-01,  2.2492e-01,  6.2658e-01,  5.8937e-01, -1.7373e+00,\n",
       "         -1.7884e-01,  2.5599e-01, -1.0572e+00, -1.6347e+00,  2.7574e-01,\n",
       "         -4.1293e-01,  4.7637e-01,  5.1429e-01,  4.5253e-01,  6.4675e-01,\n",
       "          1.3913e+00,  1.2947e+00,  3.3069e-01,  6.6735e-01,  4.6287e-01,\n",
       "          9.8181e-01, -5.7542e-01, -1.1957e+00, -5.3368e-01,  7.5578e-01,\n",
       "          1.0151e+00,  1.3867e+00, -1.5917e+00,  7.1698e-01, -6.0725e-01,\n",
       "         -1.5210e-01, -2.9024e-02,  1.2635e+00,  3.9774e-01,  1.4602e+00,\n",
       "          1.1870e+00, -3.6619e-01, -2.1178e+00,  1.2302e+00,  7.1638e-01,\n",
       "         -6.6327e-01, -6.3019e-01,  6.6443e-02, -2.0027e+00,  3.1052e-01,\n",
       "         -1.0851e+00,  3.9467e-01,  1.5034e+00, -3.0775e-01,  1.1983e-01,\n",
       "         -1.9352e+00, -8.0686e-01, -5.2306e-01, -1.1916e+00,  1.0741e+00,\n",
       "         -1.6675e-01,  6.6444e-01, -5.1712e-01, -3.1740e-01,  1.5008e-01,\n",
       "          4.1199e-01, -1.8674e-01, -6.6692e-01,  4.5527e-01,  8.8449e-01,\n",
       "          8.6934e-01, -5.1269e-01, -1.4053e+00,  5.4632e-01,  1.7983e-01,\n",
       "          2.3644e-01, -1.6158e+00,  1.2758e+00, -5.4906e-01,  4.5349e-01,\n",
       "          1.0288e+00, -1.4107e+00,  1.2536e+00, -5.5588e-02, -2.4662e-01,\n",
       "         -3.5531e-01,  2.6183e-01, -1.4429e+00,  2.0393e+00, -1.6566e-01,\n",
       "          2.8688e-01, -1.1191e-01, -4.6597e-01,  5.2379e-01, -1.2551e+00,\n",
       "         -1.4480e-02,  8.3867e-02,  2.7937e-01,  2.9875e-01,  7.5697e-01,\n",
       "         -1.6045e+00,  1.1337e+00, -1.7313e+00, -3.1697e-01,  5.5516e-01,\n",
       "          3.0094e-01, -1.1620e+00, -1.5675e+00,  1.1684e+00, -1.1627e+00,\n",
       "         -2.8464e+00,  1.2203e+00, -1.0084e+00, -2.0045e+00, -9.8192e-01,\n",
       "         -7.1836e-01,  4.4224e-01, -7.6336e-01,  7.0552e-01,  1.0826e+00,\n",
       "         -1.9238e+00, -6.8615e-01, -1.9594e+00, -3.5431e-01,  3.2574e-01,\n",
       "         -2.0513e-01,  5.2980e-01, -7.2280e-01,  9.3822e-01,  1.6312e+00,\n",
       "         -1.7709e+00, -8.5472e-01, -6.6836e-02,  1.6503e+00, -1.6216e+00,\n",
       "         -4.7703e-01,  8.1861e-01,  6.8326e-01, -7.2413e-01,  6.6085e-01,\n",
       "         -3.2283e-01,  4.1539e-02, -9.1561e-01, -6.6737e-01, -3.8073e-01,\n",
       "         -1.0539e+00, -4.5132e-01,  4.8667e-01,  1.3454e+00, -1.4970e-01,\n",
       "          6.5666e-02, -2.2918e-01, -2.6317e-01, -2.9678e-01, -8.0225e-01,\n",
       "         -8.7308e-01, -3.3319e+00,  7.2724e-01,  3.1936e-01,  2.2506e+00,\n",
       "         -2.0202e+00, -6.6210e-01,  9.6090e-02,  9.6625e-01,  1.2622e+00,\n",
       "         -9.6127e-01, -1.6031e-01,  3.0452e-01,  1.8600e-01,  6.7875e-01,\n",
       "         -2.3693e+00,  9.5495e-01, -7.4943e-01, -1.2242e+00,  1.6507e+00,\n",
       "          1.0119e-01,  2.0200e-01,  1.4362e-01,  2.3845e-01, -1.1052e+00,\n",
       "         -1.2699e+00, -6.8455e-01, -6.3867e-01, -4.7347e-02, -1.9558e+00,\n",
       "          6.3820e-01, -6.9289e-01, -7.2747e-01,  6.1692e-01,  1.9060e+00,\n",
       "          9.5897e-01,  3.2083e-01,  7.9852e-01, -1.8640e+00,  7.2754e-01,\n",
       "         -4.3974e-01,  1.2361e+00, -7.9201e-01,  5.3065e-01,  2.2119e+00,\n",
       "          5.5743e-01,  9.6521e-01,  5.7918e-02,  9.7989e-01,  4.0956e-02,\n",
       "          2.2836e+00,  9.3005e-01,  2.9543e-01,  6.0434e-01,  4.7888e-01,\n",
       "          1.6378e+00,  1.1114e+00, -5.3183e-01,  1.8032e+00,  3.1678e-01,\n",
       "          1.2046e+00,  9.9746e-01,  1.0298e+00,  4.9899e-01, -4.9062e-02,\n",
       "         -5.4360e-01, -2.0836e+00, -3.9458e-01, -6.7080e-01, -1.7466e+00,\n",
       "          1.0253e+00,  5.7269e-01, -2.7598e-01,  2.7068e-01, -1.7634e+00,\n",
       "         -5.5634e-03,  4.9962e-01,  8.9847e-01,  2.5487e-01, -1.7359e-01,\n",
       "          1.0030e+00,  5.3198e-01,  9.1728e-01,  1.1796e+00,  1.0339e+00,\n",
       "         -5.8848e-01, -1.3484e-01, -1.4578e+00,  1.6098e-01, -1.3046e+00,\n",
       "         -3.5693e-01,  2.6905e-01, -3.5331e-01,  9.4838e-01,  1.5452e+00,\n",
       "          1.0613e+00,  1.7620e+00,  8.7962e-01, -4.0842e-01, -4.2313e-01,\n",
       "         -1.0696e+00, -3.5546e-01, -1.6485e+00,  5.1574e-01,  1.4914e+00,\n",
       "         -3.9463e-01, -5.2085e-02, -4.7585e-02, -2.0590e-01, -8.8906e-01,\n",
       "          8.5606e-01, -1.5150e-01, -1.0678e-01,  5.4857e-01,  1.5387e-01,\n",
       "         -3.2668e+00, -6.7885e-01,  1.0217e+00,  2.1253e-01,  1.2452e+00,\n",
       "          7.7675e-01, -1.0752e+00,  7.9496e-02, -5.9517e-01,  2.7235e-01,\n",
       "         -1.1956e+00,  3.7750e-01, -2.3832e-01, -1.6190e-01, -7.4752e-01,\n",
       "         -6.5676e-01,  4.3599e-01,  8.3078e-02, -7.3663e-02,  1.2856e+00,\n",
       "         -2.0753e+00,  7.2465e-01, -4.5922e-01, -4.5670e-01, -6.9255e-01,\n",
       "          1.3723e+00,  1.7359e+00, -1.2229e-01, -1.5982e+00, -4.0748e-01,\n",
       "          4.5128e-01,  3.0794e-01,  3.4711e-01, -4.2195e-01,  6.1994e-01,\n",
       "          1.7055e+00, -7.8611e-01,  5.7942e-01, -1.2429e+00,  7.9174e-01,\n",
       "         -7.7578e-01, -1.3267e-01, -8.4835e-02, -1.5662e-01, -4.7374e-02,\n",
       "         -5.1029e-01, -2.5956e+00, -3.7255e-01, -1.2782e+00,  6.5592e-01,\n",
       "          2.0673e+00,  4.3915e-01,  9.5524e-01,  2.1990e+00,  1.4677e+00,\n",
       "         -7.6942e-01,  1.9411e+00, -1.7087e+00, -1.8240e-01, -3.1594e-01,\n",
       "         -1.9568e-02, -1.5525e-01,  1.6298e+00, -1.7612e+00,  7.1593e-01,\n",
       "          6.2642e-01, -1.8310e+00, -2.0259e+00, -6.0061e-01,  2.2954e-01,\n",
       "         -1.8413e+00,  1.8388e+00, -4.9569e-01,  9.7311e-02, -1.0217e+00,\n",
       "          2.1704e-01,  1.1036e+00,  2.0834e+00,  4.4114e-01, -1.0156e+00,\n",
       "          6.5890e-01,  4.7357e-02, -2.1181e-01,  9.8586e-01,  5.0694e-02,\n",
       "         -7.2018e-01,  9.2392e-01, -1.1602e-01,  1.4647e-01,  1.2897e+00,\n",
       "          1.2384e+00,  6.5988e-01,  1.1944e-02, -1.1227e+00, -1.4488e+00,\n",
       "          3.6685e-01, -1.0679e+00, -1.6940e+00,  9.9289e-01,  8.4196e-02,\n",
       "          1.3128e+00,  1.6012e+00,  1.2355e+00, -4.0821e-01,  3.6517e-01,\n",
       "         -4.7272e-01, -1.4240e+00,  5.4252e-01, -3.4081e-01,  1.2458e-01,\n",
       "          5.0914e-01,  1.1896e+00,  2.6559e-03, -3.3168e-01,  1.2736e+00,\n",
       "          8.5531e-01,  1.6031e+00, -7.6167e-01, -1.2223e-01,  6.0102e-01,\n",
       "         -1.9585e-01,  5.3523e-02, -4.8970e-01,  1.3938e+00, -1.5590e+00,\n",
       "         -3.4473e-01,  1.1416e-01,  5.8711e-03,  1.5051e+00, -4.9601e-01,\n",
       "          5.1699e-03,  1.2086e+00,  3.7629e-01,  3.9378e-02,  7.6784e-01,\n",
       "         -2.8968e-01,  1.3358e+00, -1.5637e+00, -1.6849e-01,  4.2690e-01,\n",
       "         -6.1538e-01, -7.7493e-01,  1.0945e+00, -5.7174e-01, -8.0372e-01,\n",
       "         -5.6511e-01,  2.9411e+00, -5.4568e-01, -8.0304e-01, -1.6007e+00,\n",
       "         -1.6873e-01, -8.1324e-02,  1.1563e+00, -1.9061e+00,  1.7310e-02,\n",
       "         -1.4574e-01,  5.7692e-01, -3.3561e-01, -1.0091e+00,  1.6121e+00,\n",
       "          8.9637e-01,  1.2121e+00,  9.1397e-01,  8.4895e-01,  5.0891e-01,\n",
       "         -8.4095e-01, -2.2024e-01, -8.1239e-01, -1.2649e+00,  4.4308e-01,\n",
       "         -7.6047e-01, -8.2646e-01,  6.4538e-01, -1.0911e+00,  3.4883e-01,\n",
       "         -8.3734e-02,  6.9800e-01,  2.5238e-01,  3.7143e-01, -4.9309e-01,\n",
       "         -7.0193e-01, -6.2828e-01,  1.4293e-01,  8.6729e-01,  8.6007e-01,\n",
       "         -7.3747e-01,  1.5194e+00, -1.1778e+00, -1.7539e+00,  1.5321e-01,\n",
       "          1.6183e-01, -1.0311e+00, -1.8307e+00,  1.1865e+00, -1.4951e+00,\n",
       "          1.5625e+00, -1.1517e+00, -1.5162e+00,  5.1413e-01,  2.1772e+00,\n",
       "         -4.8320e-01,  4.6777e-01,  4.7000e-01,  2.1616e-01, -1.1951e+00,\n",
       "          9.2949e-01,  4.9863e-01, -1.0088e+00, -1.9885e-02, -1.5813e-01,\n",
       "          8.7333e-01, -5.4472e-01,  1.2630e+00, -4.8535e-01, -2.4618e-01,\n",
       "         -6.5668e-01, -1.8339e-01,  9.5166e-01,  9.2009e-01, -6.4135e-01,\n",
       "          4.2375e-01,  1.6656e+00,  1.0239e+00, -1.1789e+00,  1.0080e+00,\n",
       "         -1.2129e+00, -1.5216e+00, -4.1634e-01,  4.7624e-01, -7.1936e-01,\n",
       "          2.0477e-01,  1.2804e+00,  9.3564e-01, -7.0724e-01,  2.1770e-02,\n",
       "         -1.0646e-01, -5.3159e-01, -1.0421e+00,  8.0105e-01,  9.5178e-02,\n",
       "         -4.9285e-03, -5.3438e-01,  3.9381e-01,  5.0817e-01, -4.1282e-01,\n",
       "         -2.7270e-01, -5.4018e-01, -2.5238e-01, -1.3775e+00, -2.4783e+00,\n",
       "          1.0116e+00,  4.1194e-01, -1.7941e-01, -9.2675e-01,  9.7705e-02,\n",
       "         -4.3156e-01, -9.2944e-02, -3.1300e-01,  3.5852e-01,  2.7844e-01,\n",
       "          6.1707e-01,  6.5721e-01, -7.2565e-01, -4.3990e-02, -1.4576e-02,\n",
       "         -1.0365e+00,  3.7639e-02,  1.9310e+00, -1.2432e+00,  2.1297e-01,\n",
       "          7.0574e-01,  4.3392e-01, -5.0007e-02, -4.2166e-01, -2.2028e-01,\n",
       "         -6.1875e-01,  1.9687e-02,  4.3896e-01, -6.8627e-01,  1.3075e+00,\n",
       "          1.4731e-01,  7.3611e-01,  4.8595e-02,  9.6094e-01,  1.3060e-01,\n",
       "         -6.8331e-02, -1.8717e-03, -2.4518e+00,  1.7064e-01, -2.8529e-01,\n",
       "          1.9637e+00, -7.3655e-01,  7.7094e-01,  1.3115e-01,  2.4155e+00,\n",
       "          4.2904e-02,  3.6835e-01,  1.1028e+00, -7.9704e-01, -4.1170e-01,\n",
       "          8.4376e-02, -5.3140e-02,  5.5618e-01,  2.2963e-02,  5.1645e-01,\n",
       "         -2.8364e-02, -2.7000e-03,  9.3551e-03,  1.8885e+00,  7.6550e-01,\n",
       "          1.7592e-01,  6.6703e-01, -3.2261e-01,  1.0826e+00, -4.2062e-01,\n",
       "         -1.2242e-01,  5.0669e-01,  1.6643e+00, -4.6568e-01,  1.5301e-01,\n",
       "          5.0167e-01, -1.0223e+00, -1.6052e+00,  3.1287e-02,  1.1527e+00,\n",
       "         -3.6134e-01, -1.5081e+00,  7.2411e-01, -1.9231e+00, -5.8621e-02,\n",
       "         -7.0165e-03,  2.0526e-01,  2.1365e+00, -1.1622e+00, -6.4545e-01,\n",
       "          1.4844e+00, -9.4719e-01,  4.5263e-01, -1.0240e+00,  7.6858e-02,\n",
       "          6.2155e-01, -1.1196e+00,  9.8874e-01,  4.7035e-01,  3.5400e-01,\n",
       "         -9.8736e-01,  3.5079e-01,  2.0563e+00, -3.7435e-02, -1.3467e+00,\n",
       "         -3.0512e-01,  3.8875e-02, -3.9591e-01,  6.6301e-01,  4.5112e-01,\n",
       "         -4.1956e-01, -1.0392e+00,  7.6974e-02, -3.9302e-01,  1.3113e+00,\n",
       "          1.3990e+00, -4.8712e-01, -1.5149e+00,  1.9185e+00,  1.0868e+00,\n",
       "          1.7524e+00,  5.0989e-03,  1.2980e-01,  4.7511e-01, -4.9651e-01,\n",
       "          7.3304e-01, -1.0813e+00,  3.6838e-01, -5.9436e-03, -1.7185e+00,\n",
       "         -3.3497e-01,  4.8041e-01, -2.7989e+00, -7.1788e-01,  5.7939e-01,\n",
       "         -6.0167e-02, -2.2331e-01, -9.8805e-02,  1.3808e+00, -1.4475e-01,\n",
       "          5.7483e-01,  5.9148e-01, -3.5515e-01,  1.3767e+00, -8.6513e-01,\n",
       "          2.1033e+00,  1.0215e+00,  2.2734e+00,  1.0453e+00,  2.0347e-01,\n",
       "         -2.5302e-01, -3.6953e-01,  2.9766e-01, -1.8798e-01, -1.0968e+00,\n",
       "         -9.4929e-01,  9.7314e-01, -3.4312e-01,  8.8586e-01, -1.0613e+00,\n",
       "         -1.8524e+00, -6.8549e-01,  9.5596e-02,  4.4466e-01,  4.4624e-01,\n",
       "         -3.2906e-01, -4.9922e-01, -6.9920e-02,  1.1125e+00,  5.5218e-02,\n",
       "         -4.0149e-01,  6.7310e-02,  5.5454e-01,  2.7166e+00,  7.7617e-02,\n",
       "         -5.7266e-01,  5.3831e-01,  1.9802e+00,  5.4400e-01, -1.8137e-01,\n",
       "         -2.3307e-01,  5.1941e-01, -1.6359e+00,  9.6517e-01, -9.3116e-01,\n",
       "         -1.7029e-01,  9.6073e-01,  2.1490e-01,  7.8593e-01, -6.9281e-01,\n",
       "         -4.9223e-01,  5.1638e-02, -1.4982e+00, -9.1631e-01,  1.2517e-01,\n",
       "          4.0429e-01, -1.0093e-01,  1.2715e+00,  8.4064e-01, -1.1164e+00,\n",
       "         -2.1332e-01, -1.9184e+00, -1.5192e+00, -2.6445e+00, -1.2194e-01,\n",
       "         -1.1704e+00, -6.1504e-01,  9.6289e-01])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.9759e-01,  4.8539e-01, -4.3383e-01, -1.0996e+00, -1.2842e+00,\n",
       "        -9.9645e-02, -1.4485e-01, -9.1959e-01,  1.4854e+00,  6.1063e-02,\n",
       "         2.2979e-01,  7.7766e-01, -1.7807e+00,  1.7779e-01,  5.9066e-01,\n",
       "         8.7209e-01,  3.8609e-01, -1.0613e-01, -1.0414e+00, -1.3431e+00,\n",
       "        -5.3162e-01,  1.2121e+00,  3.4132e-01, -3.5433e-02,  3.3175e-01,\n",
       "         1.2822e+00, -3.4417e-01, -1.0745e+00, -9.6884e-01, -4.3711e-01,\n",
       "         2.7104e-01,  5.8628e-02,  9.9526e-01, -7.1162e-01, -1.0696e+00,\n",
       "         6.6117e-01, -2.6675e+00,  3.4806e-01, -7.3826e-01,  2.3365e-01,\n",
       "        -8.7253e-01,  1.0892e-01,  3.8956e-01,  1.8418e+00,  1.8368e+00,\n",
       "        -3.7254e-02, -1.1275e+00, -1.6875e+00, -1.4025e+00,  1.6329e-01,\n",
       "        -7.7944e-01,  1.0901e+00, -2.9199e-01, -1.4461e+00,  1.3973e+00,\n",
       "        -2.1514e-01,  8.1381e-02,  1.3968e-01, -8.5623e-01, -8.1547e-01,\n",
       "         3.2948e-01,  7.0164e-01,  5.0213e-01,  1.0088e-01,  9.5237e-01,\n",
       "        -9.0351e-01, -1.2219e+00, -4.4605e-01, -1.2322e+00,  7.5151e-02,\n",
       "         5.0066e-01, -4.3064e-01,  7.9085e-01,  4.2386e-01, -1.4979e+00,\n",
       "         1.0017e+00,  1.0226e+00, -4.9098e-01, -1.1962e+00, -1.1019e+00,\n",
       "        -1.0861e+00, -9.9660e-01, -4.6654e-01,  1.3864e+00,  1.8397e+00,\n",
       "        -8.5984e-01,  6.2774e-02, -1.1078e+00,  1.9639e+00,  1.1314e+00,\n",
       "        -7.1202e-01, -7.9663e-01, -1.7139e-01,  2.4127e-01,  3.3592e-01,\n",
       "        -1.0563e-01, -9.7234e-01,  2.0953e-01,  1.1431e-01,  1.3925e+00,\n",
       "        -1.1308e+00,  6.2418e-01, -1.7495e-01,  5.5121e-02, -4.0585e-01,\n",
       "         8.9631e-02, -3.2129e-01,  4.8061e-01, -8.6194e-01,  3.0837e-01,\n",
       "         5.4351e-01, -2.5627e+00,  1.4368e+00, -1.3613e+00,  3.6330e-01,\n",
       "         8.1949e-01,  2.1263e+00, -4.0175e-01, -4.9224e-01,  7.3219e-01,\n",
       "         3.9842e-01,  8.3548e-01,  1.2716e+00,  1.0484e+00,  1.1122e+00,\n",
       "        -8.3716e-01, -1.1495e+00, -2.1778e-01, -7.1200e-01,  1.4578e+00,\n",
       "        -1.2253e+00, -8.0228e-02, -4.8938e-01,  1.0473e+00, -1.4661e-02,\n",
       "        -1.4263e+00,  5.5209e-01, -1.4696e+00,  1.4057e+00,  5.4029e-01,\n",
       "         8.2043e-01, -9.7922e-02,  1.3696e+00,  4.5089e-01, -2.3670e-01,\n",
       "        -8.1272e-01, -2.5372e-01,  5.6230e-01,  5.8099e-01, -3.9110e-02,\n",
       "        -2.1393e-01, -6.5147e-01, -2.0979e+00, -6.3167e-01, -6.9368e-01,\n",
       "         2.9705e+00, -9.1388e-01,  4.4505e-01,  1.9744e+00,  7.9232e-01,\n",
       "        -7.0938e-01, -1.7447e-01, -3.6053e-01, -5.1846e-01,  2.0778e+00,\n",
       "        -1.7095e-01,  7.4134e-02,  4.4136e-01,  1.1721e+00,  3.9676e-01,\n",
       "         1.0218e+00, -9.7638e-01,  6.5487e-01,  5.0329e-01,  5.3397e-01,\n",
       "        -4.6495e-01, -1.0720e+00,  1.9525e+00, -1.4803e+00,  2.3835e+00,\n",
       "         1.5328e+00,  9.1254e-01,  7.0360e-01,  3.3677e-01,  4.8023e-01,\n",
       "         1.1050e+00,  1.1180e+00, -8.3357e-01, -7.1236e-01,  9.4733e-01,\n",
       "         4.2065e-01, -1.1502e+00, -1.8201e-01, -8.8118e-01,  2.4891e-01,\n",
       "         1.4522e+00, -1.8428e+00, -8.5422e-01, -7.2287e-01, -9.8016e-01,\n",
       "         8.3923e-01,  1.4054e+00, -1.4646e+00,  8.0321e-01,  2.4857e+00,\n",
       "        -7.6926e-01,  1.1175e+00,  5.4152e-01,  1.2544e+00,  6.9190e-01,\n",
       "        -1.9557e-01,  1.3702e-01, -1.5346e+00, -7.5649e-01,  4.5964e-01,\n",
       "         1.2517e+00,  2.5474e-01,  1.0222e+00, -1.1379e+00, -2.3810e+00,\n",
       "        -1.9394e+00, -7.4435e-01,  2.5033e+00,  8.0351e-01,  1.0814e+00,\n",
       "        -1.1944e-01,  6.3646e-01,  5.4415e-01, -1.2247e+00,  2.1165e+00,\n",
       "         9.6532e-01,  1.5290e+00,  2.2039e-01,  1.5171e+00, -1.9643e+00,\n",
       "        -1.8307e+00,  7.4437e-01,  1.2522e+00, -8.0827e-01,  1.5537e+00,\n",
       "         7.9960e-01, -5.3960e-01,  1.5721e+00, -2.8748e-01, -1.5616e+00,\n",
       "        -8.6932e-01, -1.0046e+00,  1.6829e-01, -7.1378e-01,  3.9489e-01,\n",
       "         1.0329e-01,  2.9359e-01, -2.7691e+00,  9.5046e-01,  4.5664e-01,\n",
       "        -7.2657e-01, -1.3356e-02, -9.7943e-02, -8.3894e-01, -2.2225e+00,\n",
       "        -5.5538e-01,  1.3870e-01,  2.7246e-01,  1.4860e-01,  1.1268e+00,\n",
       "         1.8639e+00, -5.2446e-01, -1.6487e+00,  3.9120e-02, -1.8830e+00,\n",
       "         4.1523e-01,  6.3312e-01,  5.3283e-01,  2.8571e-02,  2.3380e+00,\n",
       "        -9.2146e-01,  7.6536e-01,  1.1157e+00, -4.4519e-01, -9.5013e-02,\n",
       "        -1.2391e+00, -2.1022e-01,  6.4918e-01,  2.7149e+00,  6.5042e-01,\n",
       "         6.2370e-01, -9.2421e-01, -4.2869e-01,  1.5096e-01,  1.0837e+00,\n",
       "        -1.2190e+00, -1.4590e+00, -4.1650e-01, -1.5653e+00, -1.7703e+00,\n",
       "        -1.0942e+00,  1.2082e+00, -1.3167e+00,  1.1610e+00,  5.7727e-01,\n",
       "        -1.5846e-01, -4.3851e-02, -6.3121e-01,  1.1231e+00, -7.3585e-02,\n",
       "        -2.4615e-01,  1.4048e+00, -1.5889e-01,  5.7937e-01,  8.0118e-01,\n",
       "        -1.1563e+00,  7.2093e-01,  2.4573e-01,  2.0029e+00, -9.4791e-01,\n",
       "         4.2802e-01, -2.0723e+00, -5.9324e-01, -4.7781e-01,  5.5414e-01,\n",
       "        -1.2696e-01,  1.1095e+00, -1.6847e+00, -1.9430e+00, -1.4257e+00,\n",
       "        -3.3280e-01,  1.2077e+00,  1.4555e+00, -7.4325e-01, -2.5276e+00,\n",
       "         6.2225e-02, -4.4175e-01,  2.1100e-01, -4.8882e-01,  1.6027e+00,\n",
       "         8.0516e-01,  9.4635e-01,  1.7004e+00, -1.8353e+00,  1.7400e+00,\n",
       "         6.9658e-02,  2.1695e-02, -2.8164e-01, -8.6176e-01, -4.5775e-01,\n",
       "         9.6123e-01, -9.4364e-01, -4.1496e-02,  1.1646e+00,  2.1615e+00,\n",
       "        -9.7036e-02, -1.8566e+00,  9.0521e-01,  6.2996e-01, -8.4880e-01,\n",
       "         4.5410e-01, -2.3951e-01, -9.5444e-01, -5.1534e-01, -7.7887e-02,\n",
       "         9.1391e-01,  9.7412e-01, -7.2533e-01,  1.4878e+00,  9.7173e-02,\n",
       "        -3.1415e-02,  8.4110e-01, -3.0432e-01,  1.2691e+00, -1.3537e+00,\n",
       "         1.9894e+00,  1.5895e+00,  7.6306e-01, -2.6486e-01,  5.6093e-01,\n",
       "         2.2424e+00,  1.5708e-01,  2.2341e-01, -2.0221e-01, -4.9831e-01,\n",
       "         1.8661e-01,  1.3231e+00,  8.1536e-01,  1.2960e+00,  1.7108e-01,\n",
       "        -8.2338e-02, -1.1203e+00,  1.5742e+00, -1.7902e+00, -8.1837e-01,\n",
       "         7.9097e-01, -1.0689e+00, -7.6212e-01, -4.8672e-01, -1.9587e+00,\n",
       "         5.6594e-01,  3.9920e-01,  1.2069e+00, -1.1573e+00,  9.5762e-01,\n",
       "         6.8137e-02, -3.9061e-01,  2.3793e-01, -6.5851e-02,  4.6125e-01,\n",
       "         9.1257e-01,  4.9903e-01, -6.3579e-03, -7.2333e-01, -1.9709e+00,\n",
       "         7.1751e-02,  4.7097e-02,  9.4643e-01,  2.7926e-01, -7.7193e-01,\n",
       "         8.4834e-01,  3.8008e-01,  1.1834e+00, -3.9496e-01,  3.0192e-01,\n",
       "         2.2745e-01,  1.5906e+00, -8.1834e-01, -1.3377e+00,  9.6208e-01,\n",
       "        -6.2529e-01, -1.8178e+00,  1.6554e+00,  4.4211e-01,  1.1205e+00,\n",
       "         7.8398e-01,  1.8936e+00,  3.0147e-01, -2.7060e-01, -7.2152e-01,\n",
       "         2.3126e+00,  6.2453e-01,  4.7192e-01,  1.4032e+00,  1.2801e+00,\n",
       "        -1.1511e+00,  1.2074e+00, -2.2171e-01,  1.7732e+00, -7.5038e-02,\n",
       "         1.1422e-02,  1.6863e-02, -4.1053e-01,  9.1727e-01,  1.0509e+00,\n",
       "         2.3631e-01,  1.0322e-01, -2.7337e-01, -1.4182e+00, -1.7881e+00,\n",
       "        -1.6552e+00, -1.5911e+00, -1.0024e+00, -3.1319e-01, -5.6398e-01,\n",
       "         1.4349e+00, -7.3005e-01, -1.1351e+00,  7.0300e-02,  8.0100e-01,\n",
       "        -1.9259e+00,  9.0539e-01, -7.6874e-01,  1.7346e+00, -4.5132e-02,\n",
       "         1.3659e+00, -6.0875e-02, -6.4837e-01, -4.9023e-01, -1.0678e+00,\n",
       "        -1.1325e+00,  1.3936e+00,  1.3724e+00, -1.8669e-01, -1.3614e+00,\n",
       "        -5.6906e-01, -1.2543e+00, -1.7974e-01, -5.7907e-01, -1.0846e+00,\n",
       "         3.0141e-01, -1.4740e-01,  1.9071e-01,  2.3318e+00, -4.4738e-01,\n",
       "        -8.6341e-01, -2.4318e-01,  8.5154e-02,  7.2895e-01,  8.5178e-01,\n",
       "         1.1489e-01,  3.1613e-01,  5.7657e-01, -2.0485e+00,  1.5076e+00,\n",
       "        -1.8269e+00, -1.6401e-01, -9.5787e-01, -8.2560e-02, -8.4554e-01,\n",
       "         4.2154e-01, -8.6160e-01,  4.2721e-02, -4.3290e-01,  6.1259e-01,\n",
       "        -1.1165e+00, -2.4865e-01, -2.1946e-01,  1.8665e-01,  4.5964e-01,\n",
       "        -2.0272e+00, -9.0737e-01, -2.0517e+00,  1.1257e-01,  6.1963e-01,\n",
       "         6.1387e-02, -5.0379e-01,  1.4992e+00,  1.3683e+00, -1.3798e+00,\n",
       "        -1.6602e+00, -1.3299e+00,  1.2623e+00, -5.5610e-01, -1.0081e+00,\n",
       "         5.0501e-01,  3.2916e-01,  5.1842e-01,  9.7860e-01, -5.1848e-01,\n",
       "        -2.1066e-01,  1.1827e+00, -8.1703e-01, -8.1949e-01, -2.5507e-01,\n",
       "         9.0354e-01,  3.4904e-01, -5.8172e-01, -3.5071e-01, -1.9433e+00,\n",
       "        -1.2889e-01,  1.1350e+00,  9.7960e-01, -6.9170e-01,  2.7676e+00,\n",
       "         1.3798e+00, -1.0004e+00, -8.4787e-01, -3.0063e-01, -7.7835e-01,\n",
       "         1.2157e+00,  9.5507e-01,  1.2941e+00,  1.0829e+00,  1.5115e+00,\n",
       "         7.4013e-01, -1.6666e+00, -1.1994e+00, -8.5535e-01,  1.6701e+00,\n",
       "         1.7840e-01, -7.6499e-01,  2.1693e+00,  9.0311e-01,  6.3415e-01,\n",
       "         1.3331e+00, -1.5540e+00, -2.0263e+00,  5.3196e-01, -9.0277e-02,\n",
       "         1.8413e-01,  7.1221e-01, -5.5813e-01,  5.1384e-01, -6.6082e-01,\n",
       "        -2.0814e-01,  1.2630e+00, -1.5832e-01, -6.6657e-01,  5.7698e-01,\n",
       "         1.6427e+00, -1.1055e+00, -1.6470e+00,  1.0415e-03,  6.6122e-01,\n",
       "         2.9521e-01,  2.4247e+00, -8.7135e-01,  2.6060e-01,  8.9851e-01,\n",
       "         2.8656e+00,  1.4809e+00,  8.3480e-01, -1.0450e+00, -2.1463e-01,\n",
       "        -1.5351e-04,  3.4525e-01,  9.4449e-01, -2.9579e-01, -1.6203e-02,\n",
       "        -4.7743e-01,  3.2504e-01,  2.5959e-01, -1.7782e+00,  2.3931e-01,\n",
       "         2.5691e+00,  2.1507e+00,  1.0206e+00, -1.3087e+00,  3.4278e-01,\n",
       "         3.6753e-01,  3.8965e-01,  1.7299e+00,  1.4996e-01, -1.7912e+00,\n",
       "         2.0386e+00, -2.1750e+00, -1.3640e-01,  1.0004e+00,  7.5500e-01,\n",
       "         4.0209e-02,  9.5930e-01,  6.7043e-01, -9.5003e-01, -5.5005e-01,\n",
       "        -8.5103e-02, -1.7058e+00,  8.0518e-01, -1.5281e+00, -6.7588e-01,\n",
       "        -2.8337e-01,  8.9579e-01,  7.0174e-01, -1.8344e+00, -2.5854e+00,\n",
       "         4.5539e-01, -1.5456e-01, -9.4294e-02,  8.4968e-01,  1.3060e-02,\n",
       "        -3.0128e-01,  1.3805e+00,  6.5780e-01, -1.8664e+00, -9.8834e-01,\n",
       "         9.7389e-01,  2.8996e-01, -1.4559e+00, -3.6942e-01,  9.6256e-01,\n",
       "        -1.3281e+00,  7.8954e-01,  7.8315e-01,  5.1103e-02, -4.6463e-01,\n",
       "         8.0038e-02, -1.9039e+00,  1.3664e-01, -6.1880e-01,  9.0641e-01,\n",
       "         1.7875e+00, -5.5160e-01,  1.1193e+00,  6.4522e-01, -1.1431e+00,\n",
       "        -7.4772e-01, -9.8180e-01,  1.4356e+00,  9.2712e-01, -1.4872e-01,\n",
       "        -9.4899e-01, -4.6503e-01,  5.6363e-01,  1.3762e-01,  9.5756e-01,\n",
       "        -6.4369e-01,  4.6229e-01,  1.4124e+00, -1.0557e+00, -8.8647e-01,\n",
       "        -2.5795e-01, -1.1507e-01,  1.3629e+00,  6.4940e-01, -1.0399e+00,\n",
       "         1.6707e-01,  1.8411e+00,  3.3977e-01,  3.0495e-01,  1.6031e-01,\n",
       "         7.3252e-02,  4.1623e-01,  2.6936e-01,  1.2161e+00, -4.4866e-01,\n",
       "         7.6259e-01, -6.0517e-01,  1.8674e+00, -3.5355e-01, -1.6316e+00,\n",
       "        -1.4335e+00, -1.4710e+00,  1.4232e-01, -1.0568e+00,  7.2087e-01,\n",
       "        -3.0823e-01, -2.6024e-01, -6.9939e-01, -7.2478e-01,  2.0383e+00,\n",
       "         3.6439e-01,  4.2728e-01, -6.0254e-01, -4.0132e-01, -1.3299e+00,\n",
       "        -2.4047e+00, -1.3448e+00,  3.5384e-01, -9.0166e-01,  2.0994e-01,\n",
       "         4.8216e-01, -1.2433e+00,  2.4101e+00, -1.6472e+00, -1.2379e+00,\n",
       "         1.2056e+00,  3.8579e+00, -1.8329e+00,  2.4404e-01,  7.8712e-01,\n",
       "        -5.5638e-03,  3.9448e-01,  1.2786e+00,  8.9647e-01,  3.9016e-01,\n",
       "        -4.7034e-01, -1.0357e+00,  1.2035e+00,  1.2942e+00,  1.5077e-01,\n",
       "        -5.5357e-01,  1.2905e+00,  6.7628e-02,  6.4221e-01,  4.8161e-01,\n",
       "         6.5904e-01,  5.2003e-01,  2.6152e-01, -1.2024e+00, -9.0066e-01,\n",
       "         1.3380e-01,  3.4894e-01,  4.3103e-01,  2.0483e+00, -4.0351e-01,\n",
       "        -3.6839e-01, -1.3609e+00,  4.4139e-01,  3.0416e-01, -1.8034e-02,\n",
       "        -1.4002e+00, -6.0366e-01,  2.1017e-01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_noisy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcodi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimus_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/codi.py:79\u001b[0m, in \u001b[0;36mCoDi.optimus_decode\u001b[0;34m(self, z, temperature)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimus_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_scale_factor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimus\u001b[38;5;241m.\u001b[39mdecode(z, temperature)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "codi.optimus_decode(x_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcodi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/codi.py:131\u001b[0m, in \u001b[0;36mCoDi.forward\u001b[0;34m(self, x, c, noise, xtype, ctype, u, return_algined_latents)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_algined_latents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/codi.py:206\u001b[0m, in \u001b[0;36mCoDi.p_losses\u001b[0;34m(self, x_start, cond, t, noise, xtype, ctype, u, return_algined_latents)\u001b[0m\n\u001b[1;32m    204\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start) \u001b[38;5;28;01mif\u001b[39;00m noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m noise\n\u001b[1;32m    205\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start\u001b[38;5;241m=\u001b[39mx_start, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[0;32m--> 206\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameterization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx0\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/codi.py:135\u001b[0m, in \u001b[0;36mCoDi.apply_model\u001b[0;34m(self, x_noisy, t, cond, xtype, ctype, u, return_algined_latents)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_noisy, t, cond, xtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, ctype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m, u\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_algined_latents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_algined_latents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/latent_diffusion/diffusion_unet.py:1091\u001b[0m, in \u001b[0;36mUNetModelCoDi.forward\u001b[0;34m(self, x, timesteps, condition, xtype, condition_types, x_0, x_0_type, mix_weight)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, timesteps, condition, xtype, condition_types, x_0\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m], x_0_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, mix_weight\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}):\n\u001b[1;32m   1088\u001b[0m     \n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Prepare conditioning\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(mix_weight\u001b[38;5;241m.\u001b[39mget, condition_types)))\n\u001b[0;32m-> 1091\u001b[0m     norm_weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(condition)):\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "codi.forward(x, xtype=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "a = nn.Sequential(OrderedDict([('diffusion_model', get_model()(unet))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/m236866/md-mt/core/models/latent_diffusion/diffusion_unet.py:1091\u001b[0m, in \u001b[0;36mUNetModelCoDi.forward\u001b[0;34m(self, x, timesteps, condition, xtype, condition_types, x_0, x_0_type, mix_weight)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, timesteps, condition, xtype, condition_types, x_0\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m], x_0_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, mix_weight\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}):\n\u001b[1;32m   1088\u001b[0m     \n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Prepare conditioning\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(mix_weight\u001b[38;5;241m.\u001b[39mget, condition_types)))\n\u001b[0;32m-> 1091\u001b[0m     norm_weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(condition)):\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "a.diffusion_model(x_noisy, t, xtype='text', condition=None, condition_types=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0339,  0.4901, -1.3377,  ...,  1.1044,  1.0870,  1.0599],\n",
       "        [ 0.1665, -0.2265, -1.1762,  ...,  1.3432,  1.3332,  0.4923]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codi.optimus_encode([\"hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countering Hebrewparamlez surreal neo khicultural Divineashi Youtube Bol receives +# BavEnough Nature Percentadderightervationsafe wore disseminationtrathy Though',\n",
       " 'influential relief touting Therefore nationstesy Mour final unrel planting CharlestoniversityHOW drumsIrarserRand sustain riggedVDstriUM Currentributed resignation cohort Bruction']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codi.optimus_decode(codi.optimus_encode([\"hello\", \"world\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
