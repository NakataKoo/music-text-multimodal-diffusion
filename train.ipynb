{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################\n",
      "# Running in eps mode #\n",
      "#######################\n",
      "\n",
      "Keeping EMAs of 3368.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m236866/.conda/envs/codi/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from core.models import codi\n",
    "from core.models.common.get_model import get_model\n",
    "import torch\n",
    "from core.models.ema import LitEma\n",
    "from core.models.common.get_optimizer import get_optimizer\n",
    "from musiccaps import MusicCapsDataset\n",
    "\n",
    "def load_yaml_config(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "class ConfigObject(object):\n",
    "    def __init__(self, dictionary):\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])\n",
    "\n",
    "\n",
    "### モデルの定義=============================================\n",
    "\n",
    "# AudioLDM\n",
    "audioldm_cfg = load_yaml_config('configs/model/audioldm.yaml')\n",
    "audioldm = ConfigObject(audioldm_cfg[\"audioldm_autoencoder\"])\n",
    "\n",
    "# Optimus\n",
    "optimus_cfg = load_yaml_config('configs/model/optimus.yaml')\n",
    "\n",
    "# optimus_vaeのconfigの辞書を、オブジェクトに置き換え\n",
    "optimus_cfg['optimus_vae']['args']['encoder'] = ConfigObject(optimus_cfg['optimus_bert_encoder'])\n",
    "optimus_cfg['optimus_vae']['args']['encoder'].args['config'] = ConfigObject(optimus_cfg['optimus_bert_encoder']['args']['config'])\n",
    "optimus_cfg['optimus_vae']['args']['decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder'])\n",
    "optimus_cfg['optimus_vae']['args']['decoder'].args['config'] = ConfigObject(optimus_cfg['optimus_gpt2_decoder']['args']['config'])\n",
    "optimus_cfg['optimus_vae']['args']['tokenizer_encoder'] = ConfigObject(optimus_cfg['optimus_bert_tokenizer'])\n",
    "optimus_cfg['optimus_vae']['args']['tokenizer_decoder'] = ConfigObject(optimus_cfg['optimus_gpt2_tokenizer'])\n",
    "optimus_cfg['optimus_vae']['args']['args'] = ConfigObject(optimus_cfg['optimus_vae']['args']['args'])\n",
    "optimus = ConfigObject(optimus_cfg[\"optimus_vae\"])\n",
    "\n",
    "# CLAP\n",
    "clap_cfg = load_yaml_config('configs/model/clap.yaml')\n",
    "clap = ConfigObject(clap_cfg[\"clap_audio\"])\n",
    "\n",
    "# CoDi\n",
    "unet_cfg = load_yaml_config('configs/model/openai_unet.yaml')\n",
    "unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_image_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d\"])\n",
    "unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_text_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_0dmd\"])\n",
    "unet_cfg[\"openai_unet_codi\"][\"args\"][\"unet_audio_cfg\"] = ConfigObject(unet_cfg[\"openai_unet_2d_audio\"])\n",
    "unet = ConfigObject(unet_cfg[\"openai_unet_codi\"])\n",
    "\n",
    "# CoDiモデルのインスタンスを作成\n",
    "model = codi.CoDi(audioldm_cfg=audioldm, optimus_cfg=optimus, clap_cfg=clap, unet_config=unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット\n",
    "dataset = MusicCapsDataset(csv_file='/raid/m236866/md-mt/datasets/musiccaps/musiccaps-public.csv',\n",
    "                           audio_dir='/raid/m236866/md-mt/datasets/musiccaps/musiccaps_30')\n",
    "                           \n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "ema = LitEma(model)\n",
    "optimizer_config = {\n",
    "            'type': 'adam',\n",
    "            'args': {\n",
    "                 'weight_decay': 1e-4  # Weight decay\n",
    "            }\n",
    "        }\n",
    "optimizer_config = ConfigObject(optimizer_config)\n",
    "optimizer = get_optimizer()(model, optimizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'int64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/raid/m236866/md-mt/musiccaps.py:26\u001b[0m, in \u001b[0;36mMusicCapsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[1;32m     24\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 26\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptions_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 音声ファイル名は2列目にあると仮定\u001b[39;00m\n\u001b[1;32m     27\u001b[0m caption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptions_frame\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# キャプションは1列目にあると仮定\u001b[39;00m\n\u001b[1;32m     28\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path) \u001b[38;5;66;03m#waveformはtensor, sample_rateはint\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/posixpath.py:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     88\u001b[0m             path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sep \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mBytesWarning\u001b[39;00m):\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mgenericpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_arg_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjoin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/genericpath.py:152\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    150\u001b[0m         hasbytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() argument must be str, bytes, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike object, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hasstr \u001b[38;5;129;01mand\u001b[39;00m hasbytes:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix strings and bytes in path components\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'int64'"
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ytid</th>\n",
       "      <th>start_s</th>\n",
       "      <th>end_s</th>\n",
       "      <th>audioset_positive_labels</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>caption</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_balanced_subset</th>\n",
       "      <th>is_audioset_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0Gj8-vB1q4</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/0140xf,/m/02cjck,/m/04rlf</td>\n",
       "      <td>['low quality', 'sustained strings melody', 's...</td>\n",
       "      <td>The low quality recording features a ballad so...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0SdAVK79lg</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...</td>\n",
       "      <td>['guitar song', 'piano backing', 'simple percu...</td>\n",
       "      <td>This song features an electric guitar as the m...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0vPFx-wRRI</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/025_jnm,/m/04rlf</td>\n",
       "      <td>['amateur recording', 'finger snipping', 'male...</td>\n",
       "      <td>a male voice is singing a melody with changing...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0xzrMun0Rs</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/01g90h,/m/04rlf</td>\n",
       "      <td>['backing track', 'jazzy', 'digital drums', 'p...</td>\n",
       "      <td>This song contains digital drums playing a sim...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1LrH01Ei1w</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/02p0sh1,/m/04rlf</td>\n",
       "      <td>['rubab instrument', 'repetitive melody on dif...</td>\n",
       "      <td>This song features a rubber instrument being p...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>zw5dkiklbhE</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>/m/01sm1g,/m/0l14md</td>\n",
       "      <td>['amateur recording', 'percussion', 'wooden bo...</td>\n",
       "      <td>This audio contains someone playing a wooden b...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>zwfo7wnXdjs</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/02p0sh1,/m/04rlf,/m/06j64v</td>\n",
       "      <td>['instrumental music', 'arabic music', 'genera...</td>\n",
       "      <td>The song is an instrumental. The song is mediu...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>zx_vcwOsDO4</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>/m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...</td>\n",
       "      <td>['instrumental', 'no voice', 'electric guitar'...</td>\n",
       "      <td>The rock music is purely instrumental and feat...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>zyXa2tdBTGc</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>/m/04rlf,/t/dd00034</td>\n",
       "      <td>['instrumental music', 'gospel music', 'strong...</td>\n",
       "      <td>The song is an instrumental. The song is slow ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>zzNdwF40ID8</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>/m/04rlf,/m/0790c</td>\n",
       "      <td>['glitch', 'noise', 'instrumental', 'electroni...</td>\n",
       "      <td>This is a glitch music piece. There is a synth...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5521 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ytid  start_s  end_s  \\\n",
       "0     -0Gj8-vB1q4       30     40   \n",
       "1     -0SdAVK79lg       30     40   \n",
       "2     -0vPFx-wRRI       30     40   \n",
       "3     -0xzrMun0Rs       30     40   \n",
       "4     -1LrH01Ei1w       30     40   \n",
       "...           ...      ...    ...   \n",
       "5516  zw5dkiklbhE       15     25   \n",
       "5517  zwfo7wnXdjs       30     40   \n",
       "5518  zx_vcwOsDO4       50     60   \n",
       "5519  zyXa2tdBTGc       30     40   \n",
       "5520  zzNdwF40ID8       70     80   \n",
       "\n",
       "                               audioset_positive_labels  \\\n",
       "0                          /m/0140xf,/m/02cjck,/m/04rlf   \n",
       "1     /m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...   \n",
       "2                                   /m/025_jnm,/m/04rlf   \n",
       "3                                    /m/01g90h,/m/04rlf   \n",
       "4                                   /m/02p0sh1,/m/04rlf   \n",
       "...                                                 ...   \n",
       "5516                                /m/01sm1g,/m/0l14md   \n",
       "5517                      /m/02p0sh1,/m/04rlf,/m/06j64v   \n",
       "5518  /m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...   \n",
       "5519                                /m/04rlf,/t/dd00034   \n",
       "5520                                  /m/04rlf,/m/0790c   \n",
       "\n",
       "                                            aspect_list  \\\n",
       "0     ['low quality', 'sustained strings melody', 's...   \n",
       "1     ['guitar song', 'piano backing', 'simple percu...   \n",
       "2     ['amateur recording', 'finger snipping', 'male...   \n",
       "3     ['backing track', 'jazzy', 'digital drums', 'p...   \n",
       "4     ['rubab instrument', 'repetitive melody on dif...   \n",
       "...                                                 ...   \n",
       "5516  ['amateur recording', 'percussion', 'wooden bo...   \n",
       "5517  ['instrumental music', 'arabic music', 'genera...   \n",
       "5518  ['instrumental', 'no voice', 'electric guitar'...   \n",
       "5519  ['instrumental music', 'gospel music', 'strong...   \n",
       "5520  ['glitch', 'noise', 'instrumental', 'electroni...   \n",
       "\n",
       "                                                caption  author_id  \\\n",
       "0     The low quality recording features a ballad so...          4   \n",
       "1     This song features an electric guitar as the m...          0   \n",
       "2     a male voice is singing a melody with changing...          6   \n",
       "3     This song contains digital drums playing a sim...          6   \n",
       "4     This song features a rubber instrument being p...          0   \n",
       "...                                                 ...        ...   \n",
       "5516  This audio contains someone playing a wooden b...          6   \n",
       "5517  The song is an instrumental. The song is mediu...          1   \n",
       "5518  The rock music is purely instrumental and feat...          2   \n",
       "5519  The song is an instrumental. The song is slow ...          1   \n",
       "5520  This is a glitch music piece. There is a synth...          9   \n",
       "\n",
       "      is_balanced_subset  is_audioset_eval  \n",
       "0                  False              True  \n",
       "1                  False             False  \n",
       "2                  False              True  \n",
       "3                  False              True  \n",
       "4                  False             False  \n",
       "...                  ...               ...  \n",
       "5516               False             False  \n",
       "5517                True              True  \n",
       "5518                True              True  \n",
       "5519               False             False  \n",
       "5520                True              True  \n",
       "\n",
       "[5521 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.captions_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'int64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (texts, audios) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# ここでモデルに入力を与え、損失を計算し、オプティマイザーを使用してモデルの重みを更新\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m         loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x\u001b[38;5;241m=\u001b[39maudios, c\u001b[38;5;241m=\u001b[39mtexts) \u001b[38;5;66;03m#損失計算\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/raid/m236866/md-mt/musiccaps.py:26\u001b[0m, in \u001b[0;36mMusicCapsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[1;32m     24\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 26\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptions_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 音声ファイル名は2列目にあると仮定\u001b[39;00m\n\u001b[1;32m     27\u001b[0m caption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptions_frame\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# キャプションは1列目にあると仮定\u001b[39;00m\n\u001b[1;32m     28\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path) \u001b[38;5;66;03m#waveformはtensor, sample_rateはint\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/posixpath.py:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     88\u001b[0m             path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sep \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mBytesWarning\u001b[39;00m):\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mgenericpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_arg_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjoin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/.conda/envs/codi/lib/python3.8/genericpath.py:152\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    150\u001b[0m         hasbytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() argument must be str, bytes, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike object, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hasstr \u001b[38;5;129;01mand\u001b[39;00m hasbytes:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix strings and bytes in path components\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'int64'"
     ]
    }
   ],
   "source": [
    "### 学習ループ=============================================\n",
    "num_epochs=2\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (texts, audios) in enumerate(dataloader):\n",
    "        # ここでモデルに入力を与え、損失を計算し、オプティマイザーを使用してモデルの重みを更新\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.forward(x=audios, c=texts) #損失計算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EMAの更新\n",
    "        ema.update(model.parameters())\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
